<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Logistic regression for binary responses: Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Bastola" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"<i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <script src="https://use.fontawesome.com/5235085b15.js"></script>

    <link rel="stylesheet" href="css/xaringan-themer-solns.css" type="text/css" />
    <link rel="stylesheet" href="css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="css/my-font.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">








layout: true
  
---

class: title-slide, middle

# .fancy[Logistic regression for binary responses: Inference]

### .fancy[Stat 230]

 May 13 2022

---

# Overview

.pull-left[
&lt;img src="Day20_files/figure-html/unnamed-chunk-1-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Today: 
&lt;br&gt;
&lt;br&gt;
.blockquote-list[
logistic regression model 
  - inference
  
Deviance
  - model comparisons
]

]

---

# The logistic model

.blockquote-list[
- Our Bernoulli responses are modeled as a function of predictors `\(X_{i}=x_{1, i}, \ldots, x_{p, i}\)` through the probability of success:
`$$Y_{i} \mid X_{i} \stackrel{\text { indep. }}{\sim} \operatorname{Bern}\left(\pi\left(X_{i}\right)\right)$$`
- Log odds of success (logit):
`$$\eta_{i}=\log \left(\frac{\pi\left(X_{i}\right)}{1-\pi\left(X_{i}\right)}\right)=\beta_{0}+\beta_{1} x_{1, i}+\cdots+\beta_{p} x_{p, i}$$`
- Probability of success:
`$$\pi\left(X_{i}\right)=\frac{e^{\eta_{i}}}{1+e^{\eta_{i}}}=\frac{e^{\beta_{0}+\beta_{1} x_{1, i}+\cdots+\beta_{p} x_{p, i}}}{1+e^{\beta_{0}+\beta_{1} x_{1, i}+\cdots+\beta_{p} x_{p, i}}}$$`
]

---

class: middle

# Generalized linear model

.blockquote.font90[
The .bold[kernel mean function] defines the expected value (mean) of `\(Y\)` as a function of `\(\eta\)`.
- in a logistic model, the kernel mean function is the logistic function `\(E(Y \mid X)=\pi(X)=\frac{e^{\eta}}{1+e^{\eta}}\)`
]

&lt;br&gt;

.blockquote.font90[
The .bold[link function] defines the linear combination `\(\eta\)` as a function of the mean of `\(Y\)`.
- in a logistic model, the link function is the logit function `\(\eta=\log (\pi /(1-\pi))\)`
- These two functions are inverses of one another.
]

---

class: middle

# MLR vs logistic inference comparison

.pull-left[
.blockquote[
.bold[MLR]
- Estimation: Maximum likelihood
- One `\(\beta\)` inference: t-distribution inference
- Model comparison inference: ANOVA F-tests
]
]
.pull-right[
.blockquote[
.bold[Logistic regression]
- Estimation: Maximum likelihood
- One `\(\beta\)` inference: z-distribution inference
- Model comparison inference: Drop-in-deviance Chi-square tests
]
]

---

class: middle

# Inference and estimation

.blockquote-list[
- Estimation done using maximum likelihood estimation (MLE)
- Likelihood is the probability of the observed data, written as a function of our unknown `\(\beta\)` 's
`$$L(\beta ; d a t a)=\prod_{i=1}^{n} \pi\left(X_{i}\right)^{y_{i}}\left(1-\pi\left(X_{i}\right)\right)^{1-y_{i}}$$`
- Find the `\(\beta^{\prime}\)` s that maximize `\(L(\beta ;\)` data `\()\)`
- Unlike SLR or MLR, there is no "closed form" for these MLE `\(\hat{\beta}_{i}\)`
- Software uses a numerical optimization method to compute the MLEs `\(\hat{\beta}_{i}\)` and the standard errors `\(S E\left(\hat{\beta}_{i}\right)\)`
]

---

class: middle

# Inference and estimation

.blockquote[
- MLE estimates of `\(\hat{\beta}_{i}\)` are approximately normally distributed and unbiased when `\(n\)` is "large enough."

.bold[Confidence intervals for one] `\(\beta_{i}\)`

- A `\(C \%\)` confidence interval for `\(\beta_{i}\)` equals
`$$\hat{\beta}_{i} \pm z^{*} S E\left(\hat{\beta}_{i}\right)$$`
where `\(z^{*}\)` is the `\((100-C) / 2\)` percentile from the `\(N(0,1)\)` distribution.
]

---

class: middle

# Inference and estimation

.blockquote[

Hypothesis tests for one `\(\beta_{i}\)`

- The usual test results given by standard regression output tests whether a parameter value (intercept or slope) is equal to 0 vs. not equal to 0 :
`$$H_{0}: \beta_{i}=0 \quad H_{A}: \beta_{i} \neq 0$$`
with a test stat of
`$$z=\frac{\hat{\beta}_{i}-0}{S E\left(\hat{\beta}_{i}\right)}$$`
The `\(N(0,1)\)` is used to compute the `\(\mathrm{p}\)`-value that is appropriate for whatever `\(H_{A}\)` is specified.
]


---

class: middle

# Inference and estimation

.blockquote[
.bold[Drop-in-deviance Model comparison tests]
- In a GLM, deviance is measures something similar to residual sum of squares
- When the GLM = MLR, deviance is the same as SSR.
- We use `\(G^{2}\)` to denote deviance of a model
- Our model comparison test compares `\(G^{2}\)` from two competing models
]


---

class: middle


# Drop in Deviance test

.blockquote.font90[
(1) .bold[Hypotheses:] 
`\begin{align*}
H_{0} &amp;: \text{ reduced model} \\
H_{A} &amp;: \text{ full model}
\end{align*}`

(2) .bold[Test Statistic:] The likelihood ratio test (LRT) stat compares the drop in deviance from the reduced to the full models
`$$L R T=G_{\text {reduced }}^{2}-G_{\text {full }}^{2}$$`
(3) When `\(n\)` is "large enough", the LRT will have a chi-square `\(\left(\chi^{2}\right)\)` distribution with `\(d f=d f_{\text {reduced }}-d f_{\text {full }}=\#\)` terms tested.

The p-value is a right tailed area
`$$\text {p-value}=P\left(\chi^{2}&gt;L R T\right)=1-p c h i s q(L R T, d f)$$`
]

---

# Drop in Deviance test

.blockquote.font80[
Special cases of drop in deviance tests:

- The overall drop in deviance test compares a null "intercept only" model to a logistic model:
`$$\begin{align*}
H_{0} &amp;: \text{ log(odds)} =\beta_{0}\\
H_{A} &amp;: \text{ log(odds)}=\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{p} x_{p}
\end{align*}$$`
- Null deviance is similar in spirit to the total sum of squares in ANOVA.
]

&lt;br&gt;

.blockquote.font80[
If our reduced and full models differ by one term, then the drop in deviance test will test the same hypotheses as the z-test (a.k.a. Wald test) for the term,
  - but the two methods of testing are not identical.
  - tests will usually agree, but if they do not, use the drop in deviance LRT test results.
]

---

# Example: NES

.blockquote.font90[The National Election Studies project recorded party identification for two random samples of people during 1980 and 2000.]


```r
nes &lt;- read.csv("https://raw.githubusercontent.com/deepbas/statdatasets/main/NES.csv")
head(nes)
```

```
      year age gender  race region     income union dem       educ
1 year1980  70   male black      S  lower 1/3    no   1 HS or less
2 year1980  67   male white     NC middle 1/3   yes   1 HS or less
3 year1980  47 female black      S  lower 1/3    no   1 HS or less
4 year1980  52 female white      W  upper 1/3   yes   0    College
5 year1980  30 female white     NC  upper 1/3    no   1 HS or less
6 year1980  37   male black     NC  upper 1/3    no   1    College
```

---

count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
*library(dplyr)
```
]
 
.panel2-nes-barplot-auto[

]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
*library(ggthemes)
```
]
 
.panel2-nes-barplot-auto[

]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
library(ggthemes)
*nes$party &lt;- recode_factor(nes$dem,
*                          `1`="Democrat",
*                          `0`="Other")
```
]
 
.panel2-nes-barplot-auto[

]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
library(ggthemes)
nes$party &lt;- recode_factor(nes$dem,
                           `1`="Democrat",
                           `0`="Other")
*ggplot(nes, aes(x=year, fill = party))
```
]
 
.panel2-nes-barplot-auto[
&lt;img src="Day20_files/figure-html/nes-barplot_auto_04_output-1.svg" width="100%" /&gt;
]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
library(ggthemes)
nes$party &lt;- recode_factor(nes$dem,
                           `1`="Democrat",
                           `0`="Other")
ggplot(nes, aes(x=year, fill = party)) +
*geom_bar(position="fill")
```
]
 
.panel2-nes-barplot-auto[
&lt;img src="Day20_files/figure-html/nes-barplot_auto_05_output-1.svg" width="100%" /&gt;
]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
library(ggthemes)
nes$party &lt;- recode_factor(nes$dem,
                           `1`="Democrat",
                           `0`="Other")
ggplot(nes, aes(x=year, fill = party)) +
 geom_bar(position="fill") +
*facet_wrap(~region)
```
]
 
.panel2-nes-barplot-auto[
&lt;img src="Day20_files/figure-html/nes-barplot_auto_06_output-1.svg" width="100%" /&gt;
]

---
count: false
 
## How does temporal changes in party ID differ across regions?
.panel1-nes-barplot-auto[

```r
library(dplyr)
library(ggthemes)
nes$party &lt;- recode_factor(nes$dem,
                           `1`="Democrat",
                           `0`="Other")
ggplot(nes, aes(x=year, fill = party)) +
 geom_bar(position="fill") +
 facet_wrap(~region) +
*scale_fill_wsj()
```
]
 
.panel2-nes-barplot-auto[
&lt;img src="Day20_files/figure-html/nes-barplot_auto_07_output-1.svg" width="100%" /&gt;
]

&lt;style&gt;
.panel1-nes-barplot-auto {
  color: black;
  width: 38.6060606060606%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 70%
}
.panel2-nes-barplot-auto {
  color: black;
  width: 59.3939393939394%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 70%
}
.panel3-nes-barplot-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 70%
}
&lt;/style&gt;






---

# Example: NES

`$$\begin{aligned}
\operatorname{odds}(\operatorname{dem} \mid x) &amp;= e^{\beta_{0}+\beta_{N E} N E+\beta_{S} S+\beta_{W} W+\beta_{2000} \text { year } 2000 +\beta_{N E: 2000} N E: \text { year } 2000+\beta_{S: 2000} S: \text { year } 2000+\beta_{W: 2000} W: \text { year } 2000}
\end{aligned}$$`

.yellow-h[Interpretation in terms of odds]


```r
nes_glm1 &lt;- glm(dem ~ region*year , data=nes, family = binomial)
*tidy(nes_glm1, conf.int=TRUE, exponentiate=TRUE)
```

```
# A tibble: 8 × 7
  term                  estimate std.error statistic p.value conf.low conf.high
  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)              0.955     0.124    -0.371 0.711      0.749     1.22 
2 regionNE                 1.03      0.182     0.155 0.877      0.720     1.47 
3 regionS                  1.57      0.162     2.79  0.00534    1.14      2.16 
4 regionW                  1.12      0.192     0.575 0.565      0.767     1.63 
5 yearyear2000             1.22      0.169     1.18  0.240      0.876     1.70 
6 regionNE:yearyear2000    1.29      0.259     0.977 0.328      0.776     2.14 
7 regionS:yearyear2000     0.531     0.221    -2.86  0.00427    0.344     0.819
8 regionW:yearyear2000     0.917     0.257    -0.338 0.735      0.553     1.52 
```


---

# Example: NES

`$$\begin{aligned}
\operatorname{logit}(\operatorname{dem} \mid x) &amp;=\beta_{0}+\beta_{N E} N E+\beta_{S} S+\beta_{W} W+\beta_{2000} \text { year } 2000 \\
&amp;+\beta_{N E: 2000} N E: \text { year } 2000+\beta_{S: 2000} S: \text { year } 2000+\beta_{W: 2000} W: \text { year } 2000
\end{aligned}$$`

.yellow-h[Interpretation in terms of log of odds]


```r
nes_glm1 &lt;- glm(dem ~ region*year , data=nes, family = binomial)
*tidy(nes_glm1, conf.int=TRUE)
```

```
# A tibble: 8 × 7
  term                  estimate std.error statistic p.value conf.low conf.high
  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)            -0.0458     0.124    -0.371 0.711     -0.289     0.197
2 regionNE                0.0281     0.182     0.155 0.877     -0.328     0.384
3 regionS                 0.451      0.162     2.79  0.00534    0.134     0.770
4 regionW                 0.110      0.192     0.575 0.565     -0.266     0.487
5 yearyear2000            0.199      0.169     1.18  0.240     -0.133     0.531
6 regionNE:yearyear2000   0.253      0.259     0.977 0.328     -0.254     0.762
7 regionS:yearyear2000   -0.633      0.221    -2.86  0.00427   -1.07     -0.199
8 regionW:yearyear2000   -0.0870     0.257    -0.338 0.735     -0.592     0.418
```


---

class: action

# &lt;i class="fa fa-pencil-square-o" style="font-size:48px;color:purple"&gt;&amp;nbsp;Your&amp;nbsp;Turn&amp;nbsp;1&lt;/i&gt;    

.pull-left-40[
![](https://media.giphy.com/media/RKApDdwsQ6jkwd6RNn/giphy.gif)
]
.pull-right-60[

&lt;br&gt;
&lt;br&gt;

.blockquote[
- Go over to the in class activity file
- Go over the class activity in your group
]
]

<div class="countdown" id="timer_627e7cc3" style="top:0;right:0;padding:3px 4px;font-size:2em;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Example: NES

.blockquote.font80[
.bold[1980 (baseline year):] The difference in log-odds between the `\(S\)` region and the `\(N C\)` (baseline) region is `\(\beta_{\text {south }}\)` :
`$$\operatorname{logit}(\text { region }=S, \text { year }=1980)-\operatorname{logit}(\text { region }=N C, \text { year }=1980)=\beta_{\text {south }}$$`
]

&lt;br&gt;

.blockquote.font80[
.bold[1980 (baseline year):] In 1980 , the odds of being a Democrat in the south was `\(1.57\)` times the odds in the north central region. (part `\(\mathrm{f}\)` )
`$$\frac{\widehat{\text{odds } (\text { region }=S, \text { year }=1980)}}{\text { odds }(\text { region }=N C, \text { year }=1980)}=e^{\hat{\beta}_{\text {south }}}=e^{0.451}=1.57$$`
- This effect is statistically significant `\((\mathrm{z}=2.79, \mathrm{p}=0.00534)\)`.
`$$\begin{array}{c}
H_{0}: \beta_{S}=0 \quad \text { test stat: } z=\frac{0.451-0}{0.162}=2.79 \\
p-\text { value }=2 \times P(Z&lt;-2.79)=2 \times \operatorname{pnorm}(-2.79)=0.00534
\end{array}$$`
]

---

# Example: NES

.blockquote.font80[
- region = S: The odds of being a Democrat in 2000 is `\(35 \%\)` lower than being a Dem in 1980 in the South region. (part h)
`$$\widehat{O R_{\text {South }}}(2000 \text { vs.1980 })=e^{\hat{\beta}_{\text {year 2000 }}} e^{\hat{\beta}_{\text {year2000:South }}(1)}=e^{0.199} e^{-0.633}=0.648$$`
]

&lt;br&gt;

.blockquote.font80[
.bold[Compare OR in S vs. NC:] `\(e^{\hat{\beta}_{2000: S \text { suth }}}=0.531\)` is the factor change between the odds ratio for the South compared to NC regions: 
`$$\frac{\widehat{O R_{\text {South }}(2000 \text{ vs } .1980)}}{O R_{N C}(2000 \text { vs. 1980 })}=e^{\hat{\beta}_{2000: \text { South }}}=e^{-0.633}=0.531$$`
- This is a statistically significant change `\((\mathrm{z}=-2.86, \mathrm{p}=0.00427\)` )
]

---

class: middle

# Deviance in GLMs

.blockquote-list[
(Residual) Deviance is the term used to measure "unexplained" variation in the response.
- In MLR: deviance `\(=\)` SSR

Small deviance:
- predicted `\(\hat{\pi}\left(X_{i}\right)\)` are close to 1 when `\(y_{i}=1\)`
- predicted `\(\hat{\pi}\left(X_{i}\right)\)` are close to 0 when `\(y_{i}=0\)`

Deviance will decrease as model terms are added.
]

---

# Deviance

.blockquote-list.font80[
Logistic GLM deviance is the difference of two likelihoods

`$$\begin{aligned}
G^{2} &amp;=2[\ln L(\bar{\pi})-\ln L(\hat{\pi}(X))] \\
&amp;=2 \sum_{i=1}^{n}\left[y_{i} \ln \left(\frac{y_{i}}{\hat{\pi}\left(X_{i}\right)}\right)+\left(1-y_{i}\right) \ln \left(\frac{1-y_{i}}{1-\hat{\pi}\left(X_{i}\right)}\right)\right]
\end{aligned}$$`
]

&lt;br&gt;

.blockquote.font80[
`\(L(\hat{\pi}(X))\)` : likelihood of the data that plugs in estimates `\(\hat{\pi}\left(X_{i}\right)\)` from the logistic model.

`\(L(\bar{\pi})\)` : likelihood of the data that plugs in estimates `\(\bar{\pi}=y_{i}\)`, basing a case's "predicted" value only on the response observed for that case.

- called a saturated model
- will always have a higher likelihood than the logistic model:
`$$L(\bar{\pi}) \geq L(\hat{\pi}(X))$$`
]

---

class: middle

# Deviance and model comparison in R

.blockquote[
`anova(my.glm)`
- gives the extra deviance explained by a term when it is added to the model above it in the table

`anova(reduced.glm, full.glm, test = "Chisq")`
- gives drop in deviance test results
]

---

class: middle

# Example: NES

.pull-left-60[

.code90[

```r
anova(nes_glm1)
Analysis of Deviance Table

Model: binomial, link: logit

Response: dem

Terms added sequentially (first to last)

            Df Deviance Resid. Df Resid. Dev
NULL                         2231     3083.3
region       3   1.4306      2228     3081.9
year         1   0.0006      2227     3081.9
region:year  3  16.3611      2224     3065.5
```
]
]

.pull-right-40[
&lt;br&gt;
&lt;br&gt;
.blockquote.font80[
Null deviance (no predictors): `\(3083.3\)`

Deviance for region model: 3081.9
- adding region drops deviance by `\(1.4306\)`
]
]

---

class: middle

# Example: NES

.pull-left-60[
.code90[

```r
anova(nes_glm1)
Analysis of Deviance Table

Model: binomial, link: logit

Response: dem

Terms added sequentially (first to last)

            Df Deviance Resid. Df Resid. Dev
NULL                         2231     3083.3
region       3   1.4306      2228     3081.9
year         1   0.0006      2227     3081.9
region:year  3  16.3611      2224     3065.5
```
]
]
.pull-right-40[
.blockquote.font80[
Deviance for region and year model: `\(3081.9\)`
- adding year drops deviance by `\(0.0006\)`

Deviance for region, year, region:year model: `\(3065.5\)` 
- adding region: year drops deviance by `\(16.3611\)`
]
]

---


class: middle

# Example: NES

.blockquote.font90[
Does the effect of year on odds of being a Democrat depend on region?

`$$\begin{aligned}
H_{0}: \log (\text { odds }) &amp;=\beta_{0}+\beta_{1} N E+\beta_{2} S+\beta_{3} W+\beta_{4} Y e a r 2000 \\
H_{A}: \log (\text { odds }) &amp;=\beta_{0}+\beta_{1} N E+\beta_{2} S+\beta_{3} W+\beta_{4} Y \text { ear } 2000+\beta_{5} N E: 2000 \\
&amp;+\beta_{6} S: 2000+\beta_{7} W: 2000
\end{aligned}$$`

]


.code90[

```r
nes_glm_red &lt;- glm(dem ~ region+year , data=nes, family = binomial) # null model
tidy(nes_glm_red)
# A tibble: 5 × 5
  term         estimate std.error statistic p.value
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)   0.0593     0.0958    0.619    0.536
2 regionNE      0.132      0.129     1.03     0.304
3 regionS       0.114      0.110     1.03     0.301
4 regionW       0.0681     0.128     0.533    0.594
5 yearyear2000  0.00203    0.0852    0.0238   0.981
```
]

---

# Example: NES

.code90[

```r
anova(nes_glm_red, nes_glm1, test = "Chisq")
Analysis of Deviance Table

Model 1: dem ~ region + year
Model 2: dem ~ region * year
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1      2227     3081.9                          
2      2224     3065.5  3   16.361 0.0009562 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
]

.blockquote.font80[
- The LRT stat equals `\(L R T=3081.9-3065.5=16.361\)`
- degrees of freedom is 3 , so the `\(p\)`-value is
`$$P\left(\chi^{2}&gt;16.361\right)=1-p c h i s q(16.361,3)=0.00096$$`
- We can conclude that the full model is better than the smaller model. There is at least one region's change in party affiliation between 1980 and 2000 that is different from the other regions.
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": ["r", "css", "yaml"],
"countIncrementalSlides": true,
"slideNumberFormat": "%current%",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
