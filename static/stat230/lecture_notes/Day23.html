<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Binomial Logistic regression: deviance</title>
    <meta charset="utf-8" />
    <meta name="author" content="Bastola" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"<i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>

  </head>
  <body>
    <textarea id="source">








layout: true
  
---

class: title-slide, middle

# .fancy[Binomial Logistic regression: deviance]

### .fancy[Stat 230]

 May 27 2022

---

# Overview

.pull-left[
&lt;img src="Day23_files/figure-html/unnamed-chunk-1-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Today: 
&lt;br&gt;
&lt;br&gt;
.blockquote-list[
Deviance

Assumptions

Residuals and case influence
]

]

---

class: middle

# Review: A Logistic Regression Model for Binomial Count Data

.blockquote[
For all `\(i=1, \ldots, n\)`,

`$$\begin{align*}
y_{i} \sim \operatorname{binomial}\left(m_{i}, \pi_{i}\right),
\end{align*}$$`

where `\(m_{i}\)` is a known number of trials for observation `\(i\)`,

`$$\begin{align*}
\pi_{i}=\frac{\exp \left(\boldsymbol{x}_{i}^{\prime} \boldsymbol{\beta}\right)}{1+\exp \left(\boldsymbol{x}_{i}^{\prime} \boldsymbol{\beta}\right)},
\end{align*}$$`

and `\(y_{1}, \ldots, y_{n}\)` are independent.
]

---

class: middle

# Overview: Binomial Distribution

Recall that for `\(y_{i} \sim \operatorname{binomial}\left(m_{i}, \pi_{i}\right)\)`, the probability mass function of `\(y_{i}\)` is

.blockquote[
`$$\begin{align*}
P\left(y_{i}=y\right) &amp;=\left\{\begin{array}{ll}
\left(\begin{array}{c}
m_{i} \\
y
\end{array}\right) \pi_{i}^{y}\left(1-\pi_{i}\right)^{m_{i}-y} &amp; \text { for } y \in\left\{0, \ldots, m_{i}\right\} \\
0 &amp; \text { otherwise }
\end{array}\right.\\
E\left(y_{i}\right) &amp;=m_{i} \pi_{i}, \quad \text { and } \operatorname{Var}\left(y_{i}\right)=m_{i} \pi_{i}\left(1-\pi_{i}\right) .
\end{align*}$$`
]

&lt;br&gt;

.blockquote[
The binomial log likelihood function is

`$$\begin{align*}
\begin{array}{c}
\ell(\boldsymbol{\beta} \mid \boldsymbol{y})=\sum_{i=1}^{n}\left[y_{i} \log \left(\frac{\pi_{i}}{1-\pi_{i}}\right)+m_{i} \log \left(1-\pi_{i}\right)\right] \\
+\text { constant }
\end{array}
\end{align*}$$`
]

---

# Deviance for Binomial responses

.blockquote.font90[
- With Binomial responses, the likelihood function is

`$$\begin{align*}
L(\beta)=\prod_{i=1}^{n}\left(\begin{array}{c}
m_{i} \\
y_{i}
\end{array}\right) \pi\left(X_{i}\right)^{y_{i}}\left(1-\pi\left(X_{i}\right)\right)^{m_{i}-y_{i}}
\end{align*}$$`

- and the deviance is

`$$\begin{align*}
G^{2} &amp;=2[\ln L(\bar{\pi})-\ln L(\hat{\pi}(X))] \\
&amp;=2 \sum_{i=1}^{n}\left[y_{i} \ln \left(\frac{y_{i}}{m_{i} \hat{\pi}\left(X_{i}\right)}\right)+\left(m_{i}-y_{i}\right) \ln \left(\frac{m_{i}-y_{i}}{m_{i}-m_{i} \hat{\pi}\left(X_{i}\right)}\right)\right]
\end{align*}$$`

- `\(L(\hat{\pi}(X)):\)` likelihood of the data that plugs in estimates `\(\hat{\pi}\left(X_{i}\right)\)` from the logistic model.
- `\(L(\bar{\pi}):\)` likelihood of the data that plugs in estimates `\(\bar{\pi}_{i}=y_{i} / m_{i}\)`

`$$\begin{align*}
L(\bar{\pi}) \geq L(\hat{\pi}(X))
\end{align*}$$`
]

---

# Logistic Regression Model vs Saturated model

.pull-left[
.yellow-h[Logistic Regression Model]
.blockquote[
- `\(y_{i} \sim \operatorname{binomial}\left(m_{i}, \pi_{i}\right)\)`
- `\(y_{1}, \ldots, y_{n}\)` independent
`$$\begin{align*}
\pi_{i}=\frac{\exp \left(\boldsymbol{x}_{\boldsymbol{i}}^{\prime} \boldsymbol{\beta}\right)}{1+\exp \left(\boldsymbol{x}_{i}^{\prime} \boldsymbol{\beta}\right)}
\end{align*}$$`
- `\(p+1\)` `\(\beta\)` parameters
- MLE: `\(\hat{\pi}_{i}=\frac{\exp \left(\boldsymbol{x}_{i}^{\prime} \hat{\boldsymbol{\beta}}\right)}{1+\exp \left(\boldsymbol{x}_{i}^{\prime} \hat{\boldsymbol{\beta}}\right)}\)`
]
]


.pull-right[
.yellow-h[Saturated Model]
&lt;br&gt;
.blockquote[
- `\(y_{i} \sim \operatorname{binomial}\left(m_{i}, \pi_{i}\right)\)`
- `\(y_{1}, \ldots, y_{n}\)` independent
- `\(\pi_{i} \in[0,1]\)` for `\(i=1, \ldots, n\)` with no other restrictions
- `\(n\)` parameters
- MLE: `\(y_{i} / m_{i}\)`
]
]

---

class: middle

# Deviance for Binomial responses

.blockquote[
Deviance for binomial models can be used for two types of hypothesis tests:
1. .bold[Drop-in-deviance:] Used to compare two models, just like in binary logistic models.
2. .bold[Goodness-of-fit:] Used to test binomial response model adequacy.
]

---

# Goodness-of-fit test

.blockquote[
Our hypotheses for the GOF test are:

`$$\begin{align*}
H_{0}&amp; : \text{ logistic model }\\
H_{A}&amp; : \text{ saturated model }
\end{align*}$$`

`\(H_{0}: Y_{i} \mid X_{i} \sim \operatorname{Binom}\left(m_{i}, \pi\left(X_{i}\right)\right)\)`
- `\(\pi\left(X_{i}\right)\)` equals the logistic function of the `\(p\)` predictor terms.

`\(H_{A}\)` : the saturated "model"
- uses the `\(n\)` empirical proportion of successes `\(\bar{\pi}=y_{i} / m_{i}\)` for each case as the probability of success for all `\(m_{i}\)` trials.
]

---

# Goodness-of-fit test

.blockquote[
- The test statistic is the residual deviance of the logistic model
`$$\begin{align*}
G^{2}=2[\ln L(\bar{\pi})-\ln L(\hat{\pi}(X))]
\end{align*}$$`
- If the "fit" (likelihood) of the logistic model is "close" then `\(G^{2}\)` is "close" to 0 and we can claim that the logistic model is adequate.
- If `\(H_{0}\)` is true and `\(m_{i}\)` 's are large, `\(G^{2}\)` will have an approximate chi-square distribution with `\(n-(p+1)\)` (model) degrees of freedom. The .bold[p-value] is the probability of getting residual deviance values larger than the observed value:
`$$\begin{align*}
p-\text { value }=1-P\left(\chi^{2}&gt;G^{2}\right)=1-\operatorname{pchisq}\left(G^{2}, d f=n-(p+1)\right)
\end{align*}$$`
The suggested rule of thumb for "large `\(m\)` " is that we want most `\(m_{i}\)` 's to be at least 5 .
]

---

class: middle

# Goodness-of-fit test conclusions

.blockquote[
.bold[Do not reject the null:] (large p-value)
- Your logistic model is adequate.
- You don't have a large enough sample size `\(n\)` to have the power to detect inadequacies in your model.
]

&lt;br&gt;

.blockquote[
.bold[Reject the null:] (small p-value)
- You have outlier(s) that are inflating the residual deviance.
- Your logistic model is inadequate.
]

---

# Goodness-of-fit test conclusions

.blockquote[
.bold[Why might a model be inadequate?]
- Your log-odds model is inadequate, it is ill-fitting and transformations are needed
- Extra-binomial variation: your response counts aren't well modeled by a Binomial model*. 

*This could mean:
- trials are not .bold[independent] for each case
- probability of success is .bold[not] constant across trials for each case
- your choice of predictors .bold[isn't] sufficient (i.e. you are missing key explanatory variables)
]

---

# Case study 21.1: Krunnit Island 

.blockquote[
- .bold[GOF] test hypotheses are
`$$\begin{align*}
H_{0}&amp; : \log(\text{odds})=\beta_{0}+\beta_{1} \log (\text {area})\\
H_{A}&amp; : \log (\text {odds}) =\alpha_{i}(\text {saturated model})
\end{align*}$$`
We can conduct a GOF test because all our `\(m_{i}\)`'s (AtRisk), are above 5
]


```r
island &lt;- case2101
island$AtRisk
```

```
 [1] 75 67 66 51 28 20 43 31 28 32 30 20 31 16 15 33 40  6
```

---

class: middle

# Case study 21.1: Krunnit Island 

.yellow-h[Test stat: residual deviance of] `\(G^{2}=12.062\)`

.font90[

```r
krunnit_glm &lt;- glm(Extinct/AtRisk ~ log(Area), family="binomial", weights=AtRisk, data = island)
summary(krunnit_glm)

Call:
glm(formula = Extinct/AtRisk ~ log(Area), family = "binomial", 
    data = island, weights = AtRisk)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.71726  -0.67722   0.09726   0.48365   1.49545  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.19620    0.11845 -10.099  &lt; 2e-16 ***
log(Area)   -0.29710    0.05485  -5.416 6.08e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 45.338  on 17  degrees of freedom
Residual deviance: 12.062  on 16  degrees of freedom
AIC: 75.394

Number of Fisher Scoring iterations: 4
```
]

---

class: middle

# Case study 21.1: Krunnit Island 

- .bold[p-value:] Using `\(18-2=16\)` degrees of freedom
`$$\begin{align*}
p\text {-value }=1-P\left(\chi^{2}&gt;12.062\right)=1-p c h i s q(12.062, d f=16)=0.7397
\end{align*}$$`

.blockquote.font90[
- The .bold[large] p-value means that we .bold[do not reject] the null hypothesis.
- Our model for the probability of extinction given log-area looks to be adequate.
]

---

# Case study 21.1: Krunnit Island 

.code90[

```r
krunnit_glm_nolog &lt;- glm(Extinct/AtRisk ~ Area, family="binomial", weights=AtRisk, data = island)
summary(krunnit_glm_nolog)

Call:
glm(formula = Extinct/AtRisk ~ Area, family = "binomial", data = island, 
    weights = AtRisk)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6526  -1.0661  -0.1877   1.0038   2.1860  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.305957   0.117339 -11.130  &lt; 2e-16 ***
Area        -0.010121   0.002684  -3.771 0.000163 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 45.338  on 17  degrees of freedom
Residual deviance: 24.661  on 16  degrees of freedom
AIC: 87.993

Number of Fisher Scoring iterations: 4
```
]
---

class: middle

# Case study 21.1: Krunnit Island 

.blockquote.font90[
- Regression of extinction on area (not logged) has residual deviance of `\(24.661.\)`

- The GOF p-value for this model is `\(0.076\)`, which suggests that this model may not be adequate

  - agrees with our EDA for the log-odds suggests
]


```r
1-pchisq(24.661, df=16)
```

```
[1] 0.07602884
```


---

# Checking Assumptions

.blockquote.font90[
Binomial logistic model as the .bold[same assumptions] as binary models:
  - .bold[Independence] of cases takes an understanding of how the data was collected.
  - Log-odds .bold[linearity] can be checked with an empirical log-odds plot against quantitative predictors and residual plots.

A third assumption is that the counts of successes `\(Y_{i}\)` has a .bold[binomial distribution]:
  - the `\(m_{i}\)` trials are independent events, and a success or failure for one trial doesn't affect the outcome of another trial, and
  - the probability of success `\(\pi\left(X_{i}\right)\)` is the same for all `\(m_{i}\)` trials.
]

---

class: middle

# Checking Assumptions

.blockquote[
- If one, or both, of these assumptions is violated, then it often induces extra-binomial variation (a.k.a. .bold[over dispersion]):
- the actual variation `\(S D\left(Y \mid X_{i}\right)\)` is larger than the binomial SD of `\(\sqrt{m_{i} \pi\left(X_{i}\right)\left(1-\pi\left(X_{i}\right)\right)}\)`
- making our reported standard errors larger and p-values too small
- .bold[Check:] use the goodness-of-fit test, when `\(m_{i}\)` are large enough, to check our binomial distribution assumption.
]

---

# Checking Assumptions

.blockquote-list[
If we do find evidence of lack-of-fit in our binomial model, then you should
- Check deviance residuals as case influence stats to see if an outlier(s) is affecting GOF results.
- Check the log odds form, change model structure, see if transformations of quantitative predictors are needed

If outliers and transformations aren't a concern, then consider an alternative model:
- binary logistic model if trial-level predictors are available
- quasi-binomial logistic model
- a model that allows for correlated trials (like a mixed-effects logistic model)
]

---

class: middle

# Case study 21.1: Krunnit Island 

.out-t[How might the Krunnit Island extinction counts violate the binomial counts model assumptions?]

--

.blockquote[
.bold[Independence:]
- This assumption implies that the extinction, or not, of all at risk species on an island are independent events.
- This could be violated if the extinction of one species makes the extinction of a second more likely.
]

---

class: middle

# Case study 21.1: Krunnit Island 

.blockquote[
.bold[Probability:]
- This assumption implies that the probability `\(\pi\left(area_{i}\right)\)` of extinction on island `\(i\)` is the same for all at risk species on island `\(i\)`.
- This could be violated if, for example, species living primarily on the interior of the island had a lower chance of extinction than species living on the coastal region.
]

---

# Residuals

.blockquote[
Pearson residuals are basically response residuals standardized based on the binomial SD:
`$$\begin{align*}
p r_{i}=\frac{y_{i}-m_{i} \hat{\pi}\left(X_{i}\right)}{\sqrt{m_{i} \hat{\pi}\left(X_{i}\right)\left(1-\hat{\pi}\left(X_{i}\right)\right)}}
\end{align*}$$`
]


&lt;br&gt;

.blockquote-list[
- `resid(my_glm, type = "pearson")`
- `augment(my_glm, type.residuals = "pearson")`
]

---

# Residuals

.blockquote[
Deviance residuals are each case's contribution to the residual deviance, with a `\(\pm\)` based on whether we over- or under-estimate a case's response (the `\(\pm\)` is denoted by `\(\left.\operatorname{sign}\left(y_{i}-m_{i} \hat{\pi}\left(X_{i}\right)\right)\right)\)` :

`$$\begin{align*}
\text{Dres}_{i} = \operatorname{sign}\left(y_{i}-m_{i} \hat{\pi}\left(X_{i}\right)\right) \sqrt{2\left[y_{i} \ln \left(\frac{y_{i}}{m_{i} \hat{\pi}\left(X_{i}\right)}\right)+\left(m_{i}-y_{i}\right) \ln \left(\frac{m_{i}-y_{i}}{m_{i}-m_{i} \hat{\pi}\left(X_{i}\right)}\right)\right]}
\end{align*}$$`
]

&lt;br&gt;

.blockquote-list[
- `resid(my_glm, type = "deviance")`
- `augment(my_glm, type.residuals = "deviance")`
]

---

class: middle

# Residuals

.blockquote[
- Pearson residuals are "easy" to interpret
- Deviance residuals are good to check if you find significant results in a GOF test.
- When `\(m_{i}\)` 's are large (at least 5), both types of residuals should be similar in value and have a `\(N(0,1)\)` distribution (approximately).
- Regardless of size of `\(m_{i}\)`, we should plot residuals vs. quantitative predictors to assess linearity of the log odds.
]

---

# Case study 21.1: Krunnit Island 

- use the `augment` command to get both sets of residuals


```r
*island_aug &lt;- augment(krunnit_glm, type.residual="pearson")

plotA &lt;- ggplot(island_aug, aes(x=`log(Area)`, y=.resid)) +
 geom_point() +
 geom_hline(yintercept = 0) +
 labs(title="Pearson residual plot")

*island_aug &lt;- augment(krunnit_glm, type.residual="deviance")

plotB &lt;- ggplot(island_aug, aes(x=`log(Area)`, y=.resid)) +
 geom_point() +
 geom_hline(yintercept = 0) +
 labs(title="Deviance residual plot")
```

---

# Case study 21.1: Krunnit Island 


```r
library(gridExtra)
grid.arrange(plotA, plotB, ncol=2)
```

&lt;img src="Day23_files/figure-html/unnamed-chunk-7-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

---

class: middle

# Residuals using `ggResidpanel`

.blockquote[
- `resid_xpanel(my_glm, type = )`: where type could be pearson or deviance (or response)
- `resid_panel(my_glm, plots = "qq", type = )`: qq plot of residuals given by type
]

---

# Case study 21.1: Krunnit Island 

.blockquote.font80[
At risk counts `\(m_{i}\)` are rather large (all cases are 6 or larger) so residuals should be approximately `\(N(0,1)\)`.
]
.code70[

```r
resid_panel(krunnit_glm, plots = "qq", type = "pearson", axis.text.size = 6, title.text.size = 6)
```

&lt;img src="Day23_files/figure-html/unnamed-chunk-8-1.svg" width="30%" style="display: block; margin: auto;" /&gt;
]

---

# Case study 21.1: Krunnit Island 

.blockquote.font80[
at risk counts `\(m_{i}\)` are the `X.weights` variable (we don't want residual values to depend on `\(m_{i}\)`)
]


.code70[

```r
resid_xpanel(krunnit_glm, type = "pearson", axis.text.size = 4, title.text.size = 6)
```

&lt;img src="Day23_files/figure-html/unnamed-chunk-9-1.svg" width="40%" style="display: block; margin: auto;" /&gt;
]


---

class: middle

# Case influence stats

.blockquote[
In a GLM, leverage measures
- both a cases's "extremeness" in terms of it's predictor values and
- the size of a case's weight `\(m_{i}\)`
]

&lt;br&gt;

.blockquote[
- cases with high values of `\(m_{i}\)` are given more weight, and hence higher leverage, in the fitted model
- Cook's distance also takes into account a cases leverage (measured both by predictor values and by `\(m_{i}\)` size) and a case's residual value.
]

---

class: middle

## Case study 21.1: Krunnit Island 

.pull-left-40[
&lt;br&gt;
&lt;br&gt;
.blockquote[
- rows 1,2 and 17 have largest leverage while case 3 looks to have the highest Cook's distance value.
]
]
.pull-right-60[

```r
plot(krunnit_glm, which=5, id.n=18)
```

&lt;img src="Day23_files/figure-html/unnamed-chunk-10-1.svg" width="100%" /&gt;
]

---

## Case study 21.1: Krunnit Island 

.code70[

```r
library(GGally)
ggnostic(krunnit_glm, columnsY = c(".hat",".cooksd"))
```

&lt;img src="Day23_files/figure-html/unnamed-chunk-11-1.svg" width="60%" style="display: block; margin: auto;" /&gt;
]

---

## Case study 21.1: Krunnit Island 

.code90[

```r
island_aug &lt;- augment(krunnit_glm, data=island, type.predict = "response")
island_aug &lt;- island_aug %&gt;% mutate(ID = row_number())
island_aug %&gt;% slice(1,2,3,17) %&gt;% select(-.sigma)
# A tibble: 4 × 10
  Island      Area AtRisk Extinct .fitted  .resid .std.resid  .hat .cooksd    ID
  &lt;fct&gt;      &lt;dbl&gt;  &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;
1 Ulkokrunni 186.      75       5  0.0602  0.233      0.277  0.293 1.63e-2     1
2 Maakrunni  106.      67       3  0.0704 -0.874     -1.00   0.242 1.41e-1     2
3 Ristikari   30.7     66      10  0.0985  1.35       1.49   0.185 2.89e-1     3
4 Tiirakari    0.2     40      13  0.328  -0.0381    -0.0445 0.266 3.59e-4    17
```
]

.font90[

```r
summary(select(island_aug, Area, AtRisk))
      Area             AtRisk     
 Min.   :  0.070   Min.   : 6.00  
 1st Qu.:  0.625   1st Qu.:22.00  
 Median :  2.150   Median :31.00  
 Mean   : 19.804   Mean   :35.11  
 3rd Qu.:  4.725   3rd Qu.:42.25  
 Max.   :185.800   Max.   :75.00  
```
]


---

## Case study 21.1: Krunnit Island 


.pull-left[

&lt;img src="Day23_files/figure-html/unnamed-chunk-14-1.svg" width="100%" /&gt;


]

.pull-right[

&lt;img src="Day23_files/figure-html/unnamed-chunk-15-1.svg" width="100%" /&gt;
]


---

# Case study 21.1: Krunnit Island 

.blockquote.font80[
Case 1 (Ulkokrunni):
- largest area and the largest number at risk `\(m_{i}\)`.
- has largest leverage but it doesn't have an large residual value so it doesn't have high Cook's distance.
]

.pull-left[
.code80[

```r
library(ggrepel)
island &lt;- island %&gt;% mutate(ID = row_number())
plot &lt;- ggplot(island, aes(x=log(Area), 
                         y = Extinct/AtRisk,
                         weight = AtRisk)) +
 geom_point() +
 geom_smooth(method="glm", se=FALSE,
 method.args = list(family="binomial")) +
 labs(title="Extinction probability as a function of area")+
 theme(plot.title = element_text(hjust=0.5, size=6, 
                                  face='bold'))  

plot +  geom_label_repel(aes(label = ID),
                  box.padding   = 0.15, 
                  point.padding = 0.3,
                  segment.color = 'grey50')
```
]
]

.pull-right[
&lt;img src="Day23_files/figure-html/data-viz-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

---

# Case study 21.1: Krunnit Island 

.blockquote.font80[
Case 17 (Tiirakari)
- second smallest area but a large number of at risk species given its small size.
- has larger leverage than case 18 which has the smallest area but smaller number at risk.
- has a small residual and low Cook's distance.

Case 3 (Ristikari)
- third largest area (30.7) but it's number at risk (66) is only one smaller than case 2 (Maakrunni) which is the second largest area (106).
- has a much larger residual than case 2, which results in it having the highest Cook's distance value in the data set.
]
&lt;br&gt;
.blockquote-list.font90[
- None of these cases is overly influential in the model it and removal of case 3 , the highest Cook's distance, changes the estimate of `\(\beta_{1}\)` from `\(0.30\)` to `\(0.33\)` and it's significance doesn't change.
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": ["r", "css", "yaml"],
"countIncrementalSlides": true,
"slideNumberFormat": "%current%",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
