---
title: "Regression"
subtitle: "<br/> STAT 220"
author: "Bastola"
date: "`r format(Sys.Date(), ' %B %d %Y')`"
output:
  xaringan::moon_reader:
    css: ["default", css/xaringan-themer-solns.css, css/my-theme.css, css/my-font.css]
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    seal: false
    nature:
      highlightStyle: googlecode  #http://arm.rbind.io/slides/xaringan.html#77 # idea, magula
      highlightLines: true
      highlightLanguage: ["r", "css", "yaml"]
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
      titleSlideClass: ["left", "middle", "inverse"]
      ratio: "16:9"
      countdown: 60000
    includes:
      in_header: header.html  
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(htmltools.preserve.raw = FALSE)


knitr::opts_chunk$set(echo = TRUE, 
                      dev = 'svg',
                      collapse = TRUE, 
                      comment = NA,  # PRINTS IN FRONT OF OUTPUT, default is '##' which comments out output
                      prompt = FALSE, # IF TRUE adds a > before each code input
                      warning = FALSE, 
                      message = FALSE,
                      fig.height = 3, 
                      fig.width = 4,
                      out.width = "100%"
                      )


# load necessary packages
library(tidyr)
library(dplyr)
library(ggplot2)
library(countdown)
library(ggthemes)
library(tidyverse)
library(stringr)
library(xaringanExtra)
xaringanExtra::use_panelset()
xaringanExtra::use_tachyons()
library(flipbookr)
library(htmlwidgets)
library(lubridate)
library(palmerpenguins)
library(fontawesome)
library(caret)
library(class)
library(patchwork)
library(tidymodels)
library(mlbench)     # for PimaIndiansDiabetes2 dataset
library(janitor)
library(parsnip)
library(kknn)
library(paletteer)
library(corrr)
library(scico)
library(yardstick)
library(probably)
library(extrafont)

yt <- 0

# fire <- read_csv("https://raw.githubusercontent.com/deepbas/statdatasets/main/Algeriafires.csv")
# fire <- fire %>% clean_names() %>% na.omit() %>% mutate_at(c(10,13), as.numeric)
# fire_raw <- fire %>% select(-c("day", "month", "year", "classes"))

data(PimaIndiansDiabetes2)
db <- PimaIndiansDiabetes2
db <- db %>% na.omit() %>% mutate(diabetes = fct_rev(factor(diabetes))) 
```


```{r xaringan-themer, include = FALSE}
# Use xaringan theme from first set
```


layout: true
  
<!-- <div class="my-footer"><span>Bastola</span></div> -->
<!-- this adds the link footer to all slides, depends on my-footer class in css-->

---
class: title-slide, middle
<!-- background-image: url("assets/title-image2.jpg") -->
background-position: 10% 90%, 100% 50%
background-size: 160px, 100% 100%

# .fancy[Regression and Classification]

### .fancy[Stat 220]

.large[Bastola]

`r format(Sys.Date(), ' %B %d %Y')`

---

class: middle

# Resampling methods

.pull-left[
<br>

<br>

> Create a series of data sets similar to the training/testing split, always used with the training set
]

.pull-right[
![](images/resampling.svg)]

.footnote[[Kuhn and Johnson (2019)](https://bookdown.org/max/FES/resampling.html)]

---

class: middle

# First, simple linear regression (SLR)

> Predicting a numeric outcome when there is just one predictor

$$ Y = \beta_0 + \beta_1 X$$
- $\beta$ values are the coefficients and $X$ is the only model predictor or feature.

---

# Bivariate data from `PimaIndiansDiabetes2`

```{r, echo=FALSE}
db_slr <- db %>% select("glucose", "insulin")
```

.pull-left[
.scroll-box-20[
```{r, echo=FALSE}
db_slr
```
]
]
.pull-right[
```{r, echo=FALSE}
ggplot(db_slr,
       mapping = aes(x = insulin, y = glucose)) +
  geom_point(color = 'firebrick') +
  labs(title = 'Scatterplot of Glucose vs. Insulin',
       x = 'Insulin',
       y = 'Glucose')+
  theme_tufte()
```
]


---


# Specification for a linear regression model

```{r}
lm_spec <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")
```

--

```{r}
lm_spec
```

---
 
# Fitting the model

```{r}
lm_fit <- lm_spec %>%
  fit(glucose ~ insulin, data = db_slr)

lm_fit
```

---

# Getting the fit

```{r}
lm_fit %>% 
  pluck("fit")
```

---

```{r}
lm_fit %>% 
  pluck("fit") %>%
  summary() #<<
```


---

```{r}
predict(lm_fit, new_data = db_slr)
```

---

# Confidence and Prediction intervals

.pull-left[
.code90[
```{r}
predict(lm_fit, new_data = db_slr, 
        type = "conf_int") #<<
```
]
]
.pull-right[
.code90[
```{r}
predict(lm_fit, new_data = db_slr, 
        type = "pred_int") #<<
```

]
]

---

# Confidence and Prediction intervals


```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}

coef <- lm_fit$fit$coefficients
estimate <- predict(lm_fit, new_data = db_slr)
conf.intervals <- predict(lm_fit, new_data = db_slr, type = "conf_int")
pred.intervals <- predict(lm_fit, new_data = db_slr, type = "pred_int")


db_plot <- db_slr %>% bind_cols(estimate, conf.intervals, pred.intervals) %>% 
  as_tibble(.name_repair = "unique")

ggplot(db_plot)+
       aes(x = insulin) +
       geom_point(aes(y = glucose), color = 'firebrick') + 
       geom_ribbon(aes(ymin = .pred_lower...4, ymax = .pred_upper...5), fill = "#006EA1", alpha = .4) +
         geom_ribbon(aes(ymin = .pred_lower...6, ymax = .pred_upper...7), fill = "#006EA1", alpha = .4) +
       geom_line(aes(y = .pred)) +
       labs(title = 'Linear model with confidence intervals',
       x = 'Insulin',
       y = 'Glucose') +
       theme_tufte()
```


---

class: middle

# Multiple linear regression (MLR)


> Predicting a continuous response with a set of $p$ predictors.
predioc
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_k X_k $$

- $\beta_i$'s are the coefficients of the model and $X_i$'s are the predictors.

---

class: middle

# Fitting a MLR

```{r}
db_mlr <- db %>% select(-diabetes)

lm_fit2 <- lm_spec %>% 
  fit(glucose ~ ., data = db_mlr) 
```

---

# Extract parameter estimates

```{r}
tidy(lm_fit2) #<<
```

---

# Predict new values

```{r}
predict(lm_fit2, new_data = db_mlr)
```

---

# Actual and predicted values

```{r}
bind_cols(
  predict(lm_fit, new_data = db_mlr), db_mlr) %>% select(glucose, .pred)
```

---

class: middle

# Data Splitting

```{r}
set.seed(1234)

db_split <- initial_split(db_mlr, 
                           prop = 0.80, 
                           strata = age, 
                           breaks = 5)

db_train <- training(db_split) 
db_test <- testing(db_split)
```


---

class: middle

# Recipe

```{r}
db_recipe <- recipe(glucose ~ ., data = db_train) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors()) %>% prep()
```

--
.code90[
```{r}
db_recipe
```
]

---

# Model Building

```{r}
lm_spec <- # your model specification
  linear_reg() %>%  # model type
  set_engine(engine = "lm") %>%  # model engine
  set_mode("regression") # model mode
```

--

```{r}
# Show your model specification
lm_spec
```

---

class: middle

# Create workflow

```{r}
lm_wflow <-
 workflow() %>%
 add_model(lm_spec) %>% 
 add_recipe(db_recipe)
```

---

# Create Validation Set

```{r}
set.seed(1234)

cv_folds <- vfold_cv(db_train, 
          v = 5, 
          strata = age,
          breaks = 5) 
```

--

```{r}
cv_folds
```

---


# Common metrics for regression


> Root mean square error (RMSE)

- the standard deviation of the residuals (prediction errors)
- smaller is better

--

> Coefficient of determination, $R^2$

- proportion of the variation in the outcome that is predictable from the predictors
- larger is better

---

# Fit the model

.code90[
```{r}
get_model <- function(x) {   # Function to extract fit
  extract_fit_parsnip(x) %>% tidy()
}
```
]

--

.code90[
```{r}
lm_wflow_eval <- lm_wflow %>% 
  fit_resamples(
    resamples = cv_folds,
    metrics = metric_set(rmse, rsq),
    control = control_resamples(
      save_pred = TRUE,
      extract = get_model) #<<
    ) 
lm_wflow_eval%>%collect_metrics()
```
]

---

# Last fit and evaluation

```{r}
last_fit_lm <- last_fit(lm_wflow, split = db_split)
```

--

```{r}
last_fit_lm %>% 
  collect_metrics()
```

---

# Extract the estimates

```{r}
lm_wflow_eval$.extracts[[1]][[1]]

```


---

# Logistic Regression

> Binary response, $Y$,  with a set of $p$ explanatory (predictor, features) variables, $X_1,....X_p$.
> We model the probability that $Y$ belongs to a particular category.


$$P(Y = 1 ) = \frac{e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}}{1 + e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}}$$

$$\text{Odds} = \frac{P(Y = 1 )}{1 - P(Y = 1 )} = e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}$$
$$\text{Log Odds} = \beta_0 + \beta_1 + \cdots + \beta_pX_p$$
---

# Logistic regression with just one predictor

```{r, echo = FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
db_plot <- db %>% mutate(y = ifelse(diabetes == "pos", 1, 0))
ggplot(db_plot, aes(x=glucose, y=y)) + 
  geom_point(aes(color=diabetes, shape = diabetes)) + 
  geom_smooth(method = glm, method.args = list(family = binomial), se = FALSE) + 
  labs(y = "Probability of diabetes", title = "Logistic regression probability of diabetes given glucose")+
  theme_tufte()+
  scale_color_wsj()
```


---


# Train and Test Split

```{r}
# Create data split for train and test
set.seed(1234)
db_single <- db %>% select(diabetes, glucose)
db_split <- initial_split(db_single, prop = 0.80, strata = diabetes)
```


```{r}
# Create training data
db_train <- db_split %>%
                    training()

# Create testing data
db_test <- db_split %>%
                    testing()
```

---

class: middle

# Steps

## 1. Call the model function
## 2. Supply the family of the model
## 3. Supply the type of model you want to fit
## 4. Fit the model

---
class: middle

```{r}
fitted_logistic_model <- logistic_reg() %>% # Call the model function
        # Set the engine/family of the model
        set_engine("glm") %>%
        # Set the mode
        set_mode("classification") %>%
        # Fit the model
        fit(diabetes~., data = db_train)
```

---

class: middle

# Tidy the Summary

```{r}
tidy(fitted_logistic_model)
```

---

# Odds Ratio

$$ODDS = \frac{probability}{1 - probability}$$

```{r}
tidy(fitted_logistic_model, exponentiate = TRUE)
```

---

# Threshold for classification

```{r, echo= FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
t <- 0.5
x.thres<- (log(t/(1-t))-fitted_logistic_model$fit$coefficients[1])/fitted_logistic_model$fit$coefficients[2]

db_plot <- db %>% mutate(y = ifelse(diabetes == "pos", 1, 0))

ggplot(db_plot, aes(x=glucose, y=y)) + 
  geom_jitter(aes(color=diabetes, shape =diabetes), height = 0.01) + 
  geom_smooth(method = glm, method.args = list(family = binomial), se = FALSE) + 
  labs(y="Probability of diabetes", title = "Probability of diabetes given glucose") + 
  geom_segment(aes(x=x.thres, xend=180,y=0.52,yend=0.52), linetype = "dashed", col = "firebrick") + 
  geom_segment(aes(x=x.thres, xend=x.thres,y=1,yend=0), linetype = "dashed") +
  geom_text(x=181, y=.50, label = "threshold = 142.31", color="blue",family="Times") + 
  annotate(geom = "rect", xmin = x.thres, xmax = 200, ymin = -.05, ymax = .05, fill = "blue", alpha = 0.1) + 
  geom_text(x=170, y = .15,label = "diabetes", color="blue",family="Times")+
  theme_tufte() + 
  xlim(c(54,200))

```

---

class: action

# <i class="fa fa-pencil-square-o" style="font-size:48px;color:purple">&nbsp;Your&nbsp;Turn&nbsp;`r (yt <- yt + 1)`</i>    

Please clone the repository on [logistic regression](https://github.com/stat220/21-logistic-regression) to your local folder.

$$P(Y = 1 ) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}$$


- Verify that the glucose value of 142.31 gives the probability of having diabetes as 1/2. 

- What value of glucose gives us have a probability threshold (of having diabetes) of 0.75?

`r countdown(minutes = 5, seconds = 00, top = 0 , color_background = "inherit", padding = "3px 4px", font_size = "2em")`


---

# Class Prediction

>  Use the predict function and supply the trained model object, test dataset and the type of variable to predict

```{r}
# Class prediction
pred_class <- predict(fitted_logistic_model, new_data = db_test,
                      type = "class")  # default 0.5 probability threshold
```

---

```{r, fig.width=6, fig.height=4.5, fig.align='center', out.width = "50%"}
bind_cols(db_test %>% select(diabetes), pred_class) %>% 
  conf_mat(diabetes, .pred_class) %>% 
  autoplot(type = "heatmap")

```

---

# Class Probabilities

```{r}
# Prediction Probabilities
pred_prob <- predict(fitted_logistic_model,
                      new_data = db_test,
                      type = "prob")
```

--

.code90[
```{r}
db_results <- db_test %>%
  bind_cols(pred_prob) %>%
  mutate(.pred_class = make_two_class_pred(.pred_pos, levels(diabetes), 
                                           threshold = .75)) %>%
  select(diabetes, glucose, contains(".pred"))
```
]

---

# Results

.pull-left-60[
.code75[
```{r}
head(db_results,12)
```
]
]
.pull-right-40[
```{r, echo=FALSE, out.width="95%"}
db_results %>%  
  conf_mat(diabetes,.pred_class) %>% 
  autoplot(type = "heatmap")
```
]

---

# Custom Metrics

```{r}
custom_metrics <- metric_set(accuracy, sens, spec, ppv)

custom_metrics(db_results,
               truth = diabetes,
               estimate = .pred_class)
```

---

# ROC-AUC (Receiver Operator Characteristic- Area Under Curve)

<!-- ROC-AUC is a performance measurement for the classification problem at various thresholds settings -->

>  Uses the class probability estimates to give us a sense of performance across the entire set of potential probability cutoffs


```{r}
db_results %>% roc_auc(truth = diabetes, .pred_pos)
```

- ROC_AUC tells how much the model is capable of distinguishing between classes.

---

# ROC-AUC

>  plotted with TPR/Recall/Sensitivity against the FPR/ (1- Specificity), where TPR is on the y-axis and FPR is on the x-axis

  + ROC curves with area = 1 under the curve (AUC) are perfect classifiers
  + ROC curves with area = 0.5 AUC are just as good as random guesses


<!--If the curve is more close to the line, lower the performance of the classifier, which is no better than a mere random guess. -->

```{r, fig.width=6, eval=FALSE, fig.height=4.5, fig.align='center', out.width = "60%"}
db_results %>%
  roc_curve(truth = diabetes, .pred_pos) %>%
  autoplot()
```

---

# ROC Curve

```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
db_results %>%
  roc_curve(truth = diabetes, .pred_pos) %>%
  autoplot()
```

---

# Decision boundary

```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
# Create data split for train and test
set.seed(123)

db_two <- db %>% select(diabetes, glucose, insulin)
db_split <- initial_split(db_two, prop = 0.80, strata = diabetes)

db_train <- db_split %>%
                    training()

# Create testing data
db_test <- db_split %>%
                    testing()

# fit the model on training set
fitted_logistic_model <- logistic_reg() %>% # Call the model function
        # Set the engine/family of the model
        set_engine("glm") %>%
        # Set the mode
        set_mode("classification") %>%
        # Fit the model
        fit(diabetes~., data = db_train)

# set-up the grid

glucose_grid <- seq(min(db_train$glucose), max(db_train$glucose), length.out = 100)
insulin_grid <- seq(min(db_train$insulin), max(db_train$insulin), length.out = 100)
plot_grid <- expand.grid(glucose = glucose_grid, insulin = insulin_grid)

pred_class <- predict(fitted_logistic_model, new_data = plot_grid,
                      type = "class")  # default 0.5 probability threshold

prediction_table <- bind_cols(plot_grid, diabetes = pred_class) %>% rename("diabetes"= ".pred_class")

ggplot(data = db_train) +
  geom_point(data = prediction_table, aes(x = insulin, y = glucose, color = diabetes), alpha = 0.2) +
  geom_point(aes(x = insulin, y = glucose, fill = diabetes), color = "black", pch = 21) +
  labs(x = "Insulin", y = "Glucose") +
  scale_fill_wsj() +
  scale_color_wsj() +
  theme_tufte() 

```

---

# Let's look at the full model

```{r}
# Create data split for train and test
set.seed(1234)
db_split <- initial_split(db, prop = 0.80, strata = diabetes)
```


```{r}
# Create training data
db_train <- db_split %>%
                    training()

# Create testing data
db_test <- db_split %>%
                    testing()
```

---

# Model Tuning with a Cross Validation

```{r}
set.seed(100)

cv_folds <-
 vfold_cv(db_train, 
          v = 5, 
          strata = diabetes)
```

---

# Recipe

```{r}
db_recipe <- recipe(diabetes ~ ., data = db_train) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors()) %>% prep()
```


# Specify the model

```{r}
log_spec <- # your model specification
  logistic_reg() %>%  # model type
  set_engine(engine = "glm") %>%  # model engine
  set_mode("classification") # model mode
```

---

class: middle

## Workflow

```{r}
log_wflow <- # new workflow object
 workflow() %>% # use workflow function
 add_recipe(db_recipe) %>%   # use the new recipe
 add_model(log_spec)   # add your model spec
```

---

class: middle

## Fit, tune, and evaluate


```{r}
log_res_2 <- 
  log_wflow %>% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(
      recall, precision, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE,
      extract = get_model) # use extract function as before
    ) 
```

---

# Extract the model

```{r}
log_res_2$.extracts[[1]][[1]]
```

---
class: middle

## Collect eh metrics

```{r}
log_res_2 %>%  collect_metrics(summarize = TRUE)
```

---

```{r}
log_pred <- log_res_2 %>%
  collect_predictions()
```

```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "50%"}
log_pred %>% 
  conf_mat(diabetes, .pred_class) %>% 
  autoplot(type = "heatmap")
```

---

```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
log_pred %>% 
  group_by(id) %>% # id contains our folds
  roc_curve(diabetes, .pred_pos) %>% 
  autoplot() + 
  theme_minimal()
```

---

# Optimal cut-off

```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
log_pred %>% 
  ggplot() +
  geom_density(aes(x = .pred_pos, 
                   fill = diabetes), 
               alpha = 0.5)+
  theme_tufte()+
  scale_fill_wsj()
```

