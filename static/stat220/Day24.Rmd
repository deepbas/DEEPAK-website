---
title: "Logistic Regression"
subtitle: "<br/> Spring 2023"
author: "Bastola"
date: "`r format(Sys.Date(), ' %B %d %Y')`"
output:
  xaringan::moon_reader:
    css: ["default", css/xaringan-themer-solns.css, css/my-theme.css, css/my-font.css]
    lib_dir: libs
    chakra: libs/remark-latest.min.js
    seal: false
    nature:
      highlightStyle: googlecode  #http://arm.rbind.io/slides/xaringan.html#77 # idea, magula
      highlightLines: true
      highlightLanguage: ["r", "css", "yaml"]
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
      titleSlideClass: ["left", "middle", "inverse"]
      ratio: "16:9"
    includes:
      in_header: header.html
editor_options: 
  chunk_output_type: console
header-includes:
    - \usepackage{caption}
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(htmltools.preserve.raw = FALSE)
options(ggrepel.max.overlaps = Inf)

knitr::opts_chunk$set(echo = TRUE, 
                      dev = 'svg',
                      collapse = TRUE, 
                      comment = NA,  # PRINTS IN FRONT OF OUTPUT, default is '##' which comments out output
                      prompt = FALSE, # IF TRUE adds a > before each code input
                      warning = FALSE, 
                      message = FALSE,
                      fig.height = 3, 
                      fig.width = 4,
                      out.width = "100%",
                      prompt = FALSE,
                      rows.print=7
                      )



# load necessary packages
library(tidyr)
library(dplyr)
library(ggplot2)
library(countdown)
library(ggthemes)
library(tidyverse)
library(stringr)
library(xaringanExtra)
xaringanExtra::use_panelset()
xaringanExtra::use_tachyons()
library(flipbookr)
library(htmlwidgets)
library(lubridate)
library(palmerpenguins)
library(fontawesome)
library(class)
library(patchwork)
library(tidymodels)
library(mlbench)     # for PimaIndiansDiabetes2 dataset
library(janitor)
library(parsnip)
library(kknn)
library(paletteer)
library(corrr)
library(scico)
library(gridExtra)


select <- dplyr::select

# Set ggplot theme
# theme_set(theme_stata(base_size = 10))

yt <- 0

standardize <- function(x, na.rm = FALSE) {
  (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm)
}

# Load the fire data
fire <- read_csv("https://raw.githubusercontent.com/deepbas/statdatasets/main/Algeriafires.csv")
fire <- fire %>% clean_names() %>% na.omit() %>% mutate_at(c(10,13), as.numeric)
fire1 <- fire %>% mutate(across(where(is.numeric), standardize))

fire_raw <- fire %>% select(temperature, isi, classes)


fire1 <- fire %>% 
  mutate(across(where(is.numeric), standardize)) %>% 
  mutate(classes = as.factor(classes))


fire_recipe <- recipe(classes ~ ., data = fire_raw) %>%
 step_scale(all_predictors()) %>%
 step_center(all_predictors()) %>%
 prep()

fire_scaled <- bake(fire_recipe, fire_raw)

fire_knn_spec <- nearest_neighbor(mode = "classification",
                             engine = "kknn",
                             weight_func = "rectangular",
                             neighbors = 5)

fire_knn_fit <- fire_knn_spec %>%
 fit(classes ~ ., data = fire_scaled)


data(PimaIndiansDiabetes2)
db <- PimaIndiansDiabetes2
db <- db %>% drop_na() %>% mutate(diabetes = fct_rev(factor(diabetes))) 

```



```{r xaringanExtra-clipboard, echo=FALSE}
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clipboard\"></i>",
    success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
    error_text = "<i class=\"fa fa-times-circle\" style=\"color: #F94144\"></i>"
  ),
  rmarkdown::html_dependency_font_awesome()
)
```


layout: true
  
---

class: title-slide, middle

# .fancy[Cross Validation and Linear Regression]

### .fancy[Stat 220]

`r format(Sys.Date(), ' %B %d %Y')`


---


class: inverse, middle

# .Large[Let's see further example of classification using simple logistic regression!]

---

.panelset[
.panel[.panel-name[Logistic Regression (LR)]
.bq.font80[
- Binary response, $Y$,  with an explanatory (predictor, features) variables, $X_1$.
- We model the probability that $Y$ belongs to a particular category.


$$P(Y = 1 ) = \frac{e^{\beta_0 + \beta_1X_1}}{1 + e^{\beta_0 + \beta_1X_1}}$$

$$\text{Odds} = \frac{P(Y = 1 )}{1 - P(Y = 1 )} = e^{\beta_0 + \beta_1X_1}$$

$$\text{Log Odds} = \beta_0 + \beta_1X_1$$
]

]


.panel[.panel-name[Visual]

```{r, echo = FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
db_plot <- db %>% mutate(y = ifelse(diabetes == "pos", 1, 0))
ggplot(db_plot, aes(x=glucose, y=y)) + 
  geom_point(aes(color=diabetes, shape = diabetes)) + 
  geom_smooth(method = glm, method.args = list(family = binomial), se = FALSE) + 
  labs(y = "Probability of diabetes", title = "Logistic regression probability of diabetes given glucose")+
  theme_tufte()+
  scale_color_wsj()
```

]

.panel[.panel-name[Data Preparation]

```{r}
# Create data split for train and test
set.seed(12345)
db_single <- db %>% select(diabetes, glucose) %>% 
  mutate(diabetes = fct_relevel(diabetes, c("neg", "pos"))) 
db_split <- initial_split(db_single, prop = 0.80)

# Create training data
db_train <- db_split %>% training()

# Create testing data
db_test <- db_split %>% testing()
```
]


.panel[.panel-name[Modeling]

```{r}
set.seed(12345)
db_recipe <- recipe(diabetes ~ ., data = db_train) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors()) %>% prep()

fitted_logistic_model <- logistic_reg(engine = "glm",  # Call the model
                                      mode = "classification") %>% 
                        fit(diabetes~., data = db_train)  # Fit the model
```

]
]

---

class: middle

# Tidy the Summary

```{r}
broom::tidy(fitted_logistic_model)
```


---

class: middle

# Odds Ratio

$$ODDS = \frac{probability}{1 - probability}$$


```{r}
broom::tidy(fitted_logistic_model, exponentiate = TRUE)
```


---

# Threshold for classification

```{r, echo= FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "60%"}
set.seed(12345)
t <- 0.5
x.thres<- (log(t/(1-t))-fitted_logistic_model$fit$coefficients[1])/fitted_logistic_model$fit$coefficients[2]

db_plot <- db %>% mutate(y = ifelse(diabetes == "pos", 1, 0))

ggplot(db_plot, aes(x=glucose, y=y)) + 
  geom_jitter(aes(color=diabetes, shape =diabetes), height = 0.01) + 
  geom_smooth(method = glm, method.args = list(family = binomial), se = FALSE) + 
  labs(y="Probability of diabetes", title = "Probability of diabetes given glucose") + 
  geom_segment(aes(x=x.thres, xend=180,y=0.50,yend=0.50), linetype = "dashed", col = "firebrick") + 
  geom_segment(aes(x=x.thres, xend=x.thres,y=1,yend=0), linetype = "dashed") +
  geom_text(x=175, y=.46, label = "threshold = 143.11", color="blue",family="Times") + 
  annotate(geom = "rect", xmin = x.thres, xmax = 200, ymin = -.05, ymax = .05, fill = "blue", alpha = 0.1) + 
  annotate(geom = "rect", xmin = 55, xmax = x.thres, ymin = 0.95, ymax = 1.05, fill = "red", alpha = 0.1) + 
  geom_text(x=170, y = .15,label = "diabetes", color="blue",family="Times")+
  theme_tufte() + 
  xlim(c(54,200))
```


---


class: middle

# Class Prediction

.code80[
```{r, fig.width=6, fig.height=4.5, fig.align='center', out.width = "50%"}
set.seed(12345)
pred_class <- predict(fitted_logistic_model,  new_data = db_test) 
bind_cols(db_test %>% select(diabetes), pred_class) %>% 
  conf_mat(diabetes, .pred_class) %>% # confusion matrix
  autoplot(type = "heatmap") # with graphics
```
]

---

# Class Probabilities with `threshold = 0.50`

```{r}
# Prediction Probabilities
library(probably)
pred_prob <- predict(fitted_logistic_model,  new_data = db_test,   type = "prob")

db_results <- db_test %>% bind_cols(pred_prob) %>%
  mutate(.pred_class = make_two_class_pred(.pred_neg, levels(diabetes), threshold = .5)) %>%
  select(diabetes, glucose, contains(".pred"))
```

```{r, echo=FALSE}
head(db_results,10)
```


---

class: middle

# Custom Metrics

.pull-left[
```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "90%"}
db_results %>%  
  conf_mat(diabetes,.pred_class) %>% 
  autoplot(type = "heatmap")
```
]

.pull-right[
```{r}
custom_metrics <- metric_set(accuracy, 
                             sens, 
                             spec, 
                             ppv)
custom_metrics(db_results,
               truth = diabetes,
               estimate = .pred_class)
```
]

---


# Class Probabilities with `threshold = 0.70`

```{r}
# Prediction Probabilities
library(probably)
pred_prob <- predict(fitted_logistic_model,  new_data = db_test,   type = "prob")

db_results <- db_test %>% bind_cols(pred_prob) %>%
  mutate(.pred_class = make_two_class_pred(.pred_neg, levels(diabetes), threshold = .70)) %>%
  select(diabetes, glucose, contains(".pred"))
```

```{r, echo=FALSE}
head(db_results,10)
```


---

class: middle

# Custom Metrics

.pull-left[
```{r, echo=FALSE, fig.width=6, fig.height=4.5, fig.align='center', out.width = "90%"}
db_results %>%  
  conf_mat(diabetes,.pred_class) %>% 
  autoplot(type = "heatmap")
```
]

.pull-right[
```{r}
custom_metrics <- metric_set(accuracy, 
                             sens, 
                             spec, 
                             ppv)
custom_metrics(db_results,
               truth = diabetes,
               estimate = .pred_class)
```
]

---

class: action, middle

# <i class="fa fa-pencil-square-o" style="font-size:48px;color:purple">&nbsp;Group&nbsp;Activity&nbsp;`r (yt <- yt + 1)`</i>    


.pull-left-40[
![](https://media.giphy.com/media/RKApDdwsQ6jkwd6RNn/giphy.gif)
]
.pull-right-60[
<br>
<br>
.bq[
- Please continue working on group activity 2
]

]

`r countdown(minutes = 10, seconds = 00, top = 0 , color_background = "inherit", padding = "3px 4px", font_size = "2em")`

