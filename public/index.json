[{"authors":null,"categories":null,"content":"Deepak Bastola is a visiting assistant professor of statistics at Carleton College. His research interests include Bayesian statistics, time series methodology, and statistical computation.\nDownload my resum√©.\n","date":1647993600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1647993600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://deepbas.netlify.app/author/deepak-bastola/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/deepak-bastola/","section":"authors","summary":"Deepak Bastola is a visiting assistant professor of statistics at Carleton College. His research interests include Bayesian statistics, time series methodology, and statistical computation.\nDownload my resum√©.","tags":null,"title":"Deepak Bastola","type":"authors"},{"authors":null,"categories":null,"content":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://deepbas.netlify.app/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"Meet your instructor Deepak Bastola ","date":1672790400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1672790400,"objectID":"08e80848897097ab85e97a023372f8bd","permalink":"https://deepbas.netlify.app/courses/stat120/","publishdate":"2023-01-04T00:00:00Z","relpermalink":"/courses/stat120/","section":"courses","summary":"A first course in statistics","tags":null,"title":"üìä STAT 120: Introduction to Statistics","type":"book"},{"authors":null,"categories":null,"content":" Table of Contents What you will learn Course overview Learning Objectives Course Requirements What you will learn Data wrangling and formatting Using the tidyverse set of libraries Exploratory data analysis including data visualization using ggplot2 Data acquisition using web-scraping Statistical learning basics of supervised and unsupervised learning Regular Expression and Text mining Reproducible research and dynamic programming using R/RStudio/RShiny Course overview Welcome to introduction to data science! This course will cover the computational side of data analysis, including data acquisition, management, and visualization tools. The course introduces principles of data-scientific, reproducible research and dynamic programming using the R/RStudio ecosystem.\nIf you took Stat 120, 230, or 250 at Carleton, then you are in good shape. It is essential to recap your basic R and R-markdown skills by the first week of the class. Specifically, I expect that everyone can load a data set into R, calculate basic summary statistics, and create basic exploratory data analysis. I will expose you to Git and GitHub version control in the first week of the class and prior exposure to these is not required.\nLearning Objectives Develop research questions that can be answered by data. Import/scrape data into R and reshape it to the form necessary for analysis. Manipulate common types of data, including numeric, categorical (factors), text, date-times, geo-location variables in order to provide insight into your data and facilitate analysis. Explore data using both graphical and numeric methods to provide insight and uncover relationships/patterns. Utilize fundamental programming concepts such as iteration, conditional execution, and functions to streamline your code. Build, tune, use, and evaluate basic statistical learning models to uncover clusters and classify observations. Draw informed conclusions from your data and communicate your findings using both written and interactive platforms. Course Requirements Class activities (5%) Individual assignments (15%) Paired projects (15%) Midterm Exams (50%) Final Project (15%) ","date":1631232000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1631232000,"objectID":"206634b0871fe67b6eec133296b05e90","permalink":"https://deepbas.netlify.app/courses/stat220/","publishdate":"2021-09-10T00:00:00Z","relpermalink":"/courses/stat220/","section":"courses","summary":"A course focusing on the computational side of data analysis","tags":null,"title":"üìä STAT 220: Introduction to Data Science","type":"book"},{"authors":null,"categories":null,"content":"Meet your instructor Deepak Bastola ","date":1616544000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1616544000,"objectID":"e9ff2be4bfb6e5a4a69a669a6fbfbe97","permalink":"https://deepbas.netlify.app/courses/stat230/","publishdate":"2021-03-24T00:00:00Z","relpermalink":"/courses/stat230/","section":"courses","summary":"In depth modeling and application of regression","tags":null,"title":"üìä STAT 230: Applied Regression Analysis","type":"book"},{"authors":null,"categories":null,"content":" ","date":1685232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685232000,"objectID":"253a89ab4bc74aae8ad49e7677a32a07","permalink":"https://deepbas.netlify.app/courses/stat120/week10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week10/","section":"courses","summary":" ","tags":null,"title":"Week 10","type":"book"},{"authors":null,"categories":null,"content":"Day 27 Slides (pdf/html)\n","date":1685232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685232000,"objectID":"8407b47c96fa1e3d87dbcd9eff3ae924","permalink":"https://deepbas.netlify.app/courses/stat220/week10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week10/","section":"courses","summary":"Day 27 Slides (pdf/html)","tags":null,"title":"Week 10","type":"book"},{"authors":null,"categories":null,"content":" ","date":1684627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684627200,"objectID":"307b83d9836c5f4b8ba99b34ac5b6197","permalink":"https://deepbas.netlify.app/courses/stat120/week9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week9/","section":"courses","summary":" ","tags":null,"title":"Week 9","type":"book"},{"authors":null,"categories":null,"content":"Day 24 Slides (pdf/html)\nDay 25 Slides (pdf/html)\n","date":1684627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684627200,"objectID":"50c41049ef7ec433c630cca69b84f0b0","permalink":"https://deepbas.netlify.app/courses/stat220/week9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week9/","section":"courses","summary":"Day 24 Slides (pdf/html)\nDay 25 Slides (pdf/html)","tags":null,"title":"Week 9","type":"book"},{"authors":null,"categories":null,"content":"","date":1684022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684022400,"objectID":"c3d2981e29dfaff5248ca8da17c74092","permalink":"https://deepbas.netlify.app/courses/stat120/week8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week8/","section":"courses","summary":"","tags":null,"title":"Week 8","type":"book"},{"authors":null,"categories":null,"content":"Day 21 Slides (pdf/html)\nDay 22 Slides (pdf/html)\nDay 23 Slides (pdf/html)\n","date":1684022400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684022400,"objectID":"9b40e3fd7e8eb1c68f93476c839c78b8","permalink":"https://deepbas.netlify.app/courses/stat220/week8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week8/","section":"courses","summary":"Day 21 Slides (pdf/html)\nDay 22 Slides (pdf/html)\nDay 23 Slides (pdf/html)","tags":null,"title":"Week 8","type":"book"},{"authors":null,"categories":null,"content":" ","date":1683417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683417600,"objectID":"f2d7c84b0306dd6531b5cd935b966ff4","permalink":"https://deepbas.netlify.app/courses/stat120/week7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week7/","section":"courses","summary":" ","tags":null,"title":"Week 7","type":"book"},{"authors":null,"categories":null,"content":"Day 18 Slides (pdf/html)\nDay 19 Slides (pdf/html)\nDay 20 Slides (pdf/html)\n","date":1683417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683417600,"objectID":"cbf5e92232f783a5b58c90603a30e169","permalink":"https://deepbas.netlify.app/courses/stat220/week7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week7/","section":"courses","summary":"Day 18 Slides (pdf/html)\nDay 19 Slides (pdf/html)\nDay 20 Slides (pdf/html)","tags":null,"title":"Week 7","type":"book"},{"authors":null,"categories":null,"content":" ","date":1682812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682812800,"objectID":"21910e2c2fe678fd76c4361305f5dd01","permalink":"https://deepbas.netlify.app/courses/stat120/week6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week6/","section":"courses","summary":" ","tags":null,"title":"Week 6","type":"book"},{"authors":null,"categories":null,"content":"Day 16 Slides (pdf/html)\nDay 17 Slides (pdf/html)\n","date":1682812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682812800,"objectID":"881b312299e43cef9596c3f292defe7b","permalink":"https://deepbas.netlify.app/courses/stat220/week6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week6/","section":"courses","summary":"Day 16 Slides (pdf/html)\nDay 17 Slides (pdf/html)","tags":null,"title":"Week 6","type":"book"},{"authors":null,"categories":null,"content":" ","date":1682208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682208000,"objectID":"7f3b0b14d01f6df4fb3e883d7b37f697","permalink":"https://deepbas.netlify.app/courses/stat120/week5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week5/","section":"courses","summary":" ","tags":null,"title":"Week 5","type":"book"},{"authors":null,"categories":null,"content":"Day 13 Slides (pdf/html)\nDay 14 Slides (pdf/html)\nDay 15 Slides (pdf/html)\n","date":1682208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682208000,"objectID":"568c73761430176f46860cb3c68a4e66","permalink":"https://deepbas.netlify.app/courses/stat220/week5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week5/","section":"courses","summary":"Day 13 Slides (pdf/html)\nDay 14 Slides (pdf/html)\nDay 15 Slides (pdf/html)","tags":null,"title":"Week 5","type":"book"},{"authors":null,"categories":null,"content":"","date":1681603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681603200,"objectID":"706b02d9e6fb8cbcf558735b8872cd32","permalink":"https://deepbas.netlify.app/courses/stat120/week4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week4/","section":"courses","summary":"","tags":null,"title":"Week 4","type":"book"},{"authors":null,"categories":null,"content":"Day 10 Slides (pdf/html)\nDay 11 Slides (pdf/html)\n","date":1681257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681257600,"objectID":"0678af490f47d8b85e40ef819921412b","permalink":"https://deepbas.netlify.app/courses/stat220/week4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week4/","section":"courses","summary":"Day 10 Slides (pdf/html)\nDay 11 Slides (pdf/html)","tags":null,"title":"Week 4","type":"book"},{"authors":null,"categories":null,"content":"","date":1680998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680998400,"objectID":"7aeff46ae3afd7ba1aec8f7432a8974a","permalink":"https://deepbas.netlify.app/courses/stat120/week3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week3/","section":"courses","summary":"","tags":null,"title":"Week 3","type":"book"},{"authors":null,"categories":null,"content":"Day 7 Slides (pdf/html)\nDay 8 Slides (pdf/html)\nDay 9 Slides (pdf/html)\n","date":1680480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680480000,"objectID":"d207397eed9dc38be3242c70a1ec0bb9","permalink":"https://deepbas.netlify.app/courses/stat220/week3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week3/","section":"courses","summary":"Day 7 Slides (pdf/html)\nDay 8 Slides (pdf/html)\nDay 9 Slides (pdf/html)","tags":null,"title":"Week 3","type":"book"},{"authors":null,"categories":null,"content":" ","date":1680393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680393600,"objectID":"d0d63021090bd5f394572c48d5c6247d","permalink":"https://deepbas.netlify.app/courses/stat120/week2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week2/","section":"courses","summary":" ","tags":null,"title":"Week 2","type":"book"},{"authors":null,"categories":null,"content":"Day 4 Slides (pdf/html)\nDay 5 Slides (pdf/html)\nDay 6 Slides (pdf/html)\n","date":1680393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680393600,"objectID":"f229677111a04328cdaa846757156cc3","permalink":"https://deepbas.netlify.app/courses/stat220/week2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week2/","section":"courses","summary":"Day 4 Slides (pdf/html)\nDay 5 Slides (pdf/html)\nDay 6 Slides (pdf/html)","tags":null,"title":"Week 2","type":"book"},{"authors":null,"categories":null,"content":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)\n","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"e234f049dd42d6117f7059542da57c47","permalink":"https://deepbas.netlify.app/courses/stat120/week1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat120/week1/","section":"courses","summary":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)","tags":null,"title":"Week 1","type":"book"},{"authors":null,"categories":null,"content":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)\n","date":1662940800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662940800,"objectID":"caf90b5615af7388cd73d0d55609001d","permalink":"https://deepbas.netlify.app/courses/stat220/week1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/week1/","section":"courses","summary":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)","tags":null,"title":"Week 1","type":"book"},{"authors":null,"categories":null,"content":"","date":1653782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653782400,"objectID":"0cefa72e8dee336b39cbbce29c55eb04","permalink":"https://deepbas.netlify.app/courses/stat230/week10/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week10/","section":"courses","summary":"","tags":null,"title":"Week 10","type":"book"},{"authors":null,"categories":null,"content":"Day 24 Slides (pdf/html)\nDay 25 Slides (pdf/html)\nDay 26 Slides (pdf/html)\n","date":1653177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653177600,"objectID":"66be6a189412328077eabd9f3bd943db","permalink":"https://deepbas.netlify.app/courses/stat230/week9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week9/","section":"courses","summary":"Day 24 Slides (pdf/html)\nDay 25 Slides (pdf/html)\nDay 26 Slides (pdf/html)","tags":null,"title":"Week 9","type":"book"},{"authors":null,"categories":null,"content":"Day 21 Slides (pdf/html)\nDay 22 Slides (pdf/html)\nDay 23 Slides (pdf/html)\n","date":1652572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652572800,"objectID":"71cf839bee7f7f0435b05be9bbd158a8","permalink":"https://deepbas.netlify.app/courses/stat230/week8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week8/","section":"courses","summary":"Day 21 Slides (pdf/html)\nDay 22 Slides (pdf/html)\nDay 23 Slides (pdf/html)","tags":null,"title":"Week 8","type":"book"},{"authors":null,"categories":null,"content":"Day 18 Slides (pdf/html)\nDay 19 Midterm II\nDay 20 Slides (pdf/html)\n","date":1652054400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652054400,"objectID":"d37214898d7a234887b9858163d525e7","permalink":"https://deepbas.netlify.app/courses/stat230/week7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week7/","section":"courses","summary":"Day 18 Slides (pdf/html)\nDay 19 Midterm II\nDay 20 Slides (pdf/html)","tags":null,"title":"Week 7","type":"book"},{"authors":null,"categories":null,"content":"Midterm Break on Monday 05/02!\nDay 16 Slides (pdf/html)\nDay 17 Slides (pdf/html)\n","date":1651449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651449600,"objectID":"570fb116342adcc6dbef4741fece8183","permalink":"https://deepbas.netlify.app/courses/stat230/week6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week6/","section":"courses","summary":"Midterm Break on Monday 05/02!\nDay 16 Slides (pdf/html)\nDay 17 Slides (pdf/html)","tags":null,"title":"Week 6","type":"book"},{"authors":null,"categories":null,"content":"Day 13 Slides (pdf/html)\nDay 14 Slides (pdf/html)\nDay 15 Slides (pdf/html)\n","date":1650844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650844800,"objectID":"d0a71aa5ff66b24d85cafe34f5e93018","permalink":"https://deepbas.netlify.app/courses/stat230/week5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week5/","section":"courses","summary":"Day 13 Slides (pdf/html)\nDay 14 Slides (pdf/html)\nDay 15 Slides (pdf/html)","tags":null,"title":"Week 5","type":"book"},{"authors":null,"categories":null,"content":"Day 10 Slides (pdf/html)\nDay 11 Midterm I\nDay 12 Slides (pdf/html)\n","date":1650240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650240000,"objectID":"c866ad397fa3702519d34124b14599b6","permalink":"https://deepbas.netlify.app/courses/stat230/week4/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week4/","section":"courses","summary":"Day 10 Slides (pdf/html)\nDay 11 Midterm I\nDay 12 Slides (pdf/html)","tags":null,"title":"Week 4","type":"book"},{"authors":null,"categories":null,"content":"Day 7 Slides (pdf/html)\nDay 8 Slides (pdf/html)\nDay 9 Slides (pdf/html)\n","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"4b02bbc11b3b707a13077e6347cc51d7","permalink":"https://deepbas.netlify.app/courses/stat230/week3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week3/","section":"courses","summary":"Day 7 Slides (pdf/html)\nDay 8 Slides (pdf/html)\nDay 9 Slides (pdf/html)","tags":null,"title":"Week 3","type":"book"},{"authors":null,"categories":null,"content":"Day 4 Slides (pdf/html)\nDay 5 Slides (pdf/html)\nDay 6 Slides (pdf/html)\n","date":1648857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648857600,"objectID":"78480c4a54a0c32157ecd36ba5afdf63","permalink":"https://deepbas.netlify.app/courses/stat230/week2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week2/","section":"courses","summary":"Day 4 Slides (pdf/html)\nDay 5 Slides (pdf/html)\nDay 6 Slides (pdf/html)","tags":null,"title":"Week 2","type":"book"},{"authors":null,"categories":null,"content":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)\n","date":1648252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648252800,"objectID":"3ade9820d006faca63ac14e1b36932e2","permalink":"https://deepbas.netlify.app/courses/stat230/week1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat230/week1/","section":"courses","summary":"Day 1 Slides (pdf/html)\nDay 2 Slides (pdf/html)\nDay 3 Slides (pdf/html)","tags":null,"title":"Week 1","type":"book"},{"authors":null,"categories":null,"content":"R markdown Cheatsheet\nggplot2 Cheatsheet\ndplyr Cheatsheet\nlubridate Cheatsheet\nstringr Cheatsheet\nregex Cheatsheet\nshiny Cheatsheet\ncaret Cheatsheet\nleaflet Cheatsheet\n","date":1641427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641427200,"objectID":"5376380bb06df1ead3ca58ff8f84290c","permalink":"https://deepbas.netlify.app/courses/stat220/cheatsheets/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/cheatsheets/","section":"courses","summary":"R markdown Cheatsheet\nggplot2 Cheatsheet\ndplyr Cheatsheet\nlubridate Cheatsheet\nstringr Cheatsheet\nregex Cheatsheet\nshiny Cheatsheet\ncaret Cheatsheet\nleaflet Cheatsheet","tags":null,"title":"Link to cheatsheets","type":"book"},{"authors":null,"categories":null,"content":"Simple Data file\nMedium Data file\nTricky Data file\nMore Tricky Data file\n","date":1641427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641427200,"objectID":"dccd113fd665dd04fa7ca86a9c0ec59f","permalink":"https://deepbas.netlify.app/courses/stat220/data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/stat220/data/","section":"courses","summary":"Simple Data file\nMedium Data file\nTricky Data file\nMore Tricky Data file","tags":null,"title":"Link to datasets","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://deepbas.netlify.app/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Deepak Bastola"],"categories":["machine learning","data science","prediction"],"content":"It would be nice to predict the number of positive covid cases depending on past cases evolution. Regression models based on recurrent neural networks (RNNs) are proven to identify patterns in time series data and this allows us to make accurate short-term predictions.\nThe model used in the following example is based on long-term short-term memory (LSTM) model that uses more than one features to make informed predictions. LSTMs are recurrent neural networks that avoid the vanishing gradient problem prevalent in feed-forward type of algorithms by imposing filtering mechanisms in the gates using a technique known as back-propagation.\nThe following set of codes loads all the required Python libraries, packages, and subroutines required for LSTM modeling. This blog post is just intended to give a high level summary of how to realize a covid case count prediction in the United States using some convenient features readily available.\n# Import various libraries and routines needed for computation import math import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt import keras.backend as K from math import sqrt from numpy import concatenate from matplotlib import pyplot from pandas import read_csv, DataFrame from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.metrics import mean_squared_error, mean_absolute_error from keras.models import Sequential from keras.layers import Dense, Dropout, LSTM from keras.callbacks import EarlyStopping from datetime import date, timedelta, datetime # Read in the data file that has relevant features df = pd.read_csv('covid_final.csv') dataset = df.set_index(['date']) # Drop the last 10 row as they are incomplete dataset.drop(dataset.tail(10).index, inplace = True) values = dataset.values # Store the indexes (i.e., dates) date_index = dataset.index # Clean up the dataset more for predictions and inverse transformations (Re-scaling) data_clean = dataset.copy() data_clean_ext = dataset.copy() data_clean_ext['new_cases_predictions'] = data_clean_ext['new_cases_smoothed'] data_clean.tail() new_cases_smoothed reproduction_rate new_tests_smoothed_per_thousand new_vaccinations_smoothed_per_million people_fully_vaccinated_per_hundred total_boosters_per_hundred stringency_index date 2022-03-08 38934.286 0.65 2.748 621 65.24 28.89 53.24 2022-03-09 36641.429 0.66 2.699 601 65.25 28.91 53.24 2022-03-10 36330.429 0.69 2.613 583 65.27 28.94 53.24 2022-03-11 36104.714 0.71 2.580 557 65.29 28.97 53.24 2022-03-12 35464.143 0.71 2.561 540 65.30 28.99 53.24 # number of rows in the data nrows = data_clean.shape[0] The day-to-day case counts can be regarded as a time series and the data needs to be prepared before training a supervised learning model. For LSTM, the data is composed of inputs and outputs, and the inputs can be seen as a moving window blocks consisting of the feature values to predict the outcome. The size of the window is a free parameter that the user must optimize.\n# Convert the data to numpy values np_data_unscaled = np.array(data_clean) np_data = np.reshape(np_data_unscaled, (nrows, -1)) # ensure all data is float values = values.astype('float64') # Transform the data by scaling each feature to a range between 0 and 1 scaler = MinMaxScaler() np_data_scaled = scaler.fit_transform(np_data_unscaled) # Creating a separate scaler that works on a single column for scaling predictions scaler_pred = MinMaxScaler() df_cases = pd.DataFrame(data_clean_ext['new_cases_smoothed']) np_cases_scaled = scaler_pred.fit_transform(df_cases) In LSTM methodology, it is required to reshape the input to be a 3D tensor of samples, time steps, and features. This is more important when we are fitting the model later.\n# Set the sequence length - this is the timeframe used to make a single prediction sequence_length = 31 # rolling window size # Prediction Index index_cases = dataset.columns.get_loc(\u0026quot;new_cases_smoothed\u0026quot;) # Split the training data into train and train data sets # As a first step, we get the number of rows to train the model on 80% of the data train_data_len = math.ceil(np_data_scaled.shape[0] * 0.8) # Create the training and test data train_data = np_data_scaled[0:train_data_len, :] test_data = np_data_scaled[train_data_len - sequence_length:, :] # The RNN needs data with the format of [samples, time steps, features] # Here, we create N samples, sequence_length time steps per sample, and 6 features def partition_dataset(sequence_length, data): x, y = [], [] data_len = data.shape[0] for i in range(sequence_length, data_len): x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn y.append(data[i, index_cases]) #contains the prediction values for validation, for single-step prediction # Convert the x and y to numpy arrays x = np.array(x) y = np.array(y) return x, y # Generate training data and test data x_train, y_train = partition_dataset(sequence_length, train_data) x_test, y_test = partition_dataset(sequence_length, test_data) # Configure the neural network model model = Sequential() # Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables n_neurons = x_train.shape[1] * x_train.shape[2] model.add(LSTM(n_neurons, return_sequences=False, input_shape=(x_train.shape[1], x_train.shape[2]))) model.add(Dense(1)) # Check-points and early stopping parameters make our modeling easier from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # Compiling the LSTM model.compile(optimizer = 'adam', loss = 'mean_squared_error') # Specfy the file and file path for the best model checkpoint_path = 'my_best_model.hdf5' checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min') earlystopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose =0) callbacks = [checkpoint, earlystopping] # Training the model epochs = 300 batch_size = 20 history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks = callbacks, verbose = 0) # Load the best model from tensorflow.keras.models import load_model model_from_saved_checkpoint = load_model(checkpoint_path) # Plot training \u0026amp; validation loss values plt.figure(figsize=(16,7)) plt.plot(history.history['loss'], label='train') plt.plot(history.history['val_loss'], label='test') plt.legend() plt.show() # Get the predicted values y_pred_scaled = model_from_saved_checkpoint.predict(x_test) # Unscale the predicted values y_pred = scaler_pred.inverse_transform(y_pred_scaled) # reshape y_test_unscaled = scaler_pred.inverse_transform(y_test.reshape(-1, 1)) # Mean Absolute Error (MAE) MAE = mean_absolute_error(y_test_unscaled, y_pred) print(f'Median Absolute Error (MAE): {np.round(MAE, 2)}') # Mean Absolute Percentage Error (MAPE) MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100 print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %') # Median Absolute Percentage Error (MDAPE) MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled)) ) * 100 print(f'Median Absolute Percentage Error (MDAPE): {np.round(MDAPE, 2)} %') # Plot of the true and predicted case counts plt.plot(y_test_unscaled, label='True') plt.plot(y_pred, label='LSTM') plt.title(\u0026quot;LSTM's_Prediction\u0026quot;) plt.xlabel('Time steps') plt.ylabel('Cases') plt.legend() plt.show() # New data frame for predicting the next day count new_df = data_clean[-sequence_length:] # gets the last N days N = sequence_length # Get the values of the last N day cases counts # scale the data to be values between 0 and 1 last_N_days = new_df[-sequence_length:].values last_N_days_scaled = scaler.transform(last_N_days) # Create an empty list and Append past N days X_test_new = [] X_test_new.append(last_N_days_scaled) # Convert the X_test data set to a numpy array and reshape the data pred_cases_scaled = model_from_saved_checkpoint.predict(np.array(X_test_new)) pred_cases_unscaled = scaler_pred.inverse_transform(pred_cases_scaled.reshape(-1, 1)) # Print last price, predicted price, and change percent for the next day cases_today = np.round(new_df['new_cases_smoothed'][-1]) predicted_cases = np.round(pred_cases_unscaled.ravel()[0]) change_percent = np.round(100 - (cases_today * 100)/predicted_cases) # Code used to produce this article in jupyter notebook in hugo academic blog post !jupyter nbconvert covid_analysis.ipynb --to markdown --NbConvertApp.output_files_dir=. !cat covid_analysis.md | tee -a index.md !rm covid_analysis.md ","date":1647993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647993600,"objectID":"290915bf36768f5fbd9b8dae910b59e0","permalink":"https://deepbas.netlify.app/2022/03/23/how-to-predict-covid-case-counts-using-machine-learning-models/","publishdate":"2022-03-23T00:00:00Z","relpermalink":"/2022/03/23/how-to-predict-covid-case-counts-using-machine-learning-models/","section":"post","summary":"It would be nice to predict the number of positive covid cases depending on past cases evolution. Regression models based on recurrent neural networks (RNNs) are proven to identify patterns in time series data and this allows us to make accurate short-term predictions.","tags":[],"title":"How to predict covid case counts using machine learning models?","type":"post"},{"authors":null,"categories":["R"],"content":" R Markdown This is a R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can use asterisk mark to provide emphasis, such as *italics* or **bold** to produce italics or bold.\nYou can create lists with a combination of dash, plus, or asterisk :\n- Item 1 - Item 2 - Item 3 + Subitem 1 * Item 4 Item 1 Item 2 Item 3 Subitem 1 Item 4 You can embed Latex equations in-line as $\\frac{1}{n} \\sum_{i=1}^{n} x_{i}$ to produce \\(\\frac{1}{n} \\sum_{i=1}^{n} x_{i}\\) or in a new line as $$\\text{Var}(X) = \\frac{1}{n-1}\\sum_{i-1}^{n} (x_{i} - \\bar{x})^2 $$ to produce\n\\[\\text{Var}(X) = \\frac{1}{n-1}\\sum_{i-1}^{n} (x_{i} - \\bar{x})^2 \\]\nEmbed an R code chunk: ```r Use back ticks to create a block of code ``` You can also evaluate and display the results of R code. Each tasks can be accomplished in a suitably labeled chunk like the following:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA ) Figure 1: A fancy pie chart. Read in data files simple_data \u0026lt;- read.csv(\u0026quot;https://deepbas.io/data/simple-1.dat\u0026quot;, ) summary(simple_data) ## initials state age time ## Length:3 Length:3 Min. :45.0 Length:3 ## Class :character Class :character 1st Qu.:47.5 Class :character ## Mode :character Mode :character Median :50.0 Mode :character ## Mean :52.0 ## 3rd Qu.:55.5 ## Max. :61.0 knitr::kable(simple_data, format = \u0026quot;html\u0026quot;) initials state age time vib MA 61 6:01 adc TX 45 5:45 kme CT 50 4:19 Hide the code Entering echo = FALSE option in the R chunk prevents the R code from being printed to your document and you just see the results/outputs.\ninitials state age time vib MA 61 6:01 adc TX 45 5:45 kme CT 50 4:19 ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"e4b616406659ad12fce5ad382dfb0e1f","permalink":"https://deepbas.netlify.app/2020/12/01/simple-r-markdown-example/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/2020/12/01/simple-r-markdown-example/","section":"post","summary":"R Markdown This is a R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown"],"title":"Simple R Markdown Example","type":"post"},{"authors":null,"categories":null,"content":"It would be nice to predict the number of positive covid cases depending on past case evolution. Regression models based on recurrent neural networks (RNNs) are proven to identify patterns in time series data and this allows us to make accurate short-term predictions.\nThe model used in the following example is based on long-term short-term memory (LSTM) model that uses more than one feature to make informed predictions. LSTMs are recurrent neural networks that avoid the vanishing gradient problem prevalent in feed-forward type of algorithms by imposing filtering mechanisms in the gates using a technique known as back-propagation.\nThe following set of codes loads all the required Python libraries, packages, and subroutines required for LSTM modeling. This blog post is just intended to give a high level summary of how to realize a covid case count prediction in the United States using some convenient features readily available.\n# Import various libraries and routines needed for computation import math import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt import keras.backend as K from math import sqrt from numpy import concatenate from matplotlib import pyplot from pandas import read_csv, DataFrame from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.metrics import mean_squared_error, mean_absolute_error from keras.models import Sequential from keras.layers import Dense, Dropout, LSTM from keras.callbacks import EarlyStopping from datetime import date, timedelta, datetime # Read in the data file that has relevant features df = pd.read_csv('covid_final.csv') dataset = df.set_index(['date']) # Drop the last 10 row as they are incomplete dataset.drop(dataset.tail(10).index, inplace = True) values = dataset.values # Store the indexes (i.e., dates) date_index = dataset.index # Clean up the dataset more for predictions and inverse transformations (Re-scaling) data_clean = dataset.copy() data_clean_ext = dataset.copy() data_clean_ext['new_cases_predictions'] = data_clean_ext['new_cases_smoothed'] data_clean.tail() new_cases_smoothed reproduction_rate new_tests_smoothed_per_thousand new_vaccinations_smoothed_per_million people_fully_vaccinated_per_hundred total_boosters_per_hundred stringency_index date 2022-03-08 38934.286 0.65 2.748 621 65.24 28.89 53.24 2022-03-09 36641.429 0.66 2.699 601 65.25 28.91 53.24 2022-03-10 36330.429 0.69 2.613 583 65.27 28.94 53.24 2022-03-11 36104.714 0.71 2.580 557 65.29 28.97 53.24 2022-03-12 35464.143 0.71 2.561 540 65.30 28.99 53.24 # number of rows in the data nrows = data_clean.shape[0] The day-to-day case counts can be regarded as a time series and the data needs to be prepared before training a supervised learning model. For LSTM, the data is composed of inputs and outputs, and the inputs can be seen as a moving window blocks consisting of the feature values to predict the outcome. The size of the window is a free parameter that the user must optimize.\n# Convert the data to numpy values np_data_unscaled = np.array(data_clean) np_data = np.reshape(np_data_unscaled, (nrows, -1)) # ensure all data is float values = values.astype('float64') # Transform the data by scaling each feature to a range between 0 and 1 scaler = MinMaxScaler() np_data_scaled = scaler.fit_transform(np_data_unscaled) # Creating a separate scaler that works on a single column for scaling predictions scaler_pred = MinMaxScaler() df_cases = pd.DataFrame(data_clean_ext['new_cases_smoothed']) np_cases_scaled = scaler_pred.fit_transform(df_cases) In LSTM methodology, it is required to reshape the input to be a 3D tensor of samples, time steps, and features. This is more important when we are fitting the model later.\n# Set the sequence length - this is the timeframe used to make a single prediction sequence_length = 31 # rolling window size # Prediction Index index_cases = dataset.columns.get_loc(\u0026quot;new_cases_smoothed\u0026quot;) # Split the training data into train and train data sets # As a first step, we get the number of rows to train the model on 80% of the data train_data_len = math.ceil(np_data_scaled.shape[0] * 0.8) # Create the training and test data train_data = np_data_scaled[0:train_data_len, :] test_data = np_data_scaled[train_data_len - sequence_length:, :] # The RNN needs data with the format of [samples, time steps, features] # Here, we create N samples, sequence_length time steps per sample, and 6 features def partition_dataset(sequence_length, data): x, y = [], [] data_len = data.shape[0] for i in range(sequence_length, data_len): x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn y.append(data[i, index_cases]) #contains the prediction values for validation, for single-step prediction # Convert the x and y to numpy arrays x = np.array(x) y = np.array(y) return x, y # Generate training data and test data x_train, y_train = partition_dataset(sequence_length, train_data) x_test, y_test = partition_dataset(sequence_length, test_data) # Configure the neural network model model = Sequential() # Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables n_neurons = x_train.shape[1] * x_train.shape[2] model.add(LSTM(n_neurons, return_sequences=False, input_shape=(x_train.shape[1], x_train.shape[2]))) model.add(Dense(1)) # Check-points and early stopping parameters make our modeling easier from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping # Compiling the LSTM model.compile(optimizer = 'adam', loss = 'mean_squared_error') # Specfy the file and file path for the best model checkpoint_path = 'my_best_model.hdf5' checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min') earlystopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose =0) callbacks = [checkpoint, earlystopping] # Training the model epochs = 300 batch_size = 20 history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), callbacks = callbacks, verbose = 0) # Load the best model from tensorflow.keras.models import load_model model_from_saved_checkpoint = load_model(checkpoint_path) # Plot training \u0026amp; validation loss values plt.figure(figsize=(16,7)) plt.plot(history.history['loss'], label='train') plt.plot(history.history['val_loss'], label='test') plt.legend() plt.show() # Get the predicted values y_pred_scaled = model_from_saved_checkpoint.predict(x_test) # Unscale the predicted values y_pred = scaler_pred.inverse_transform(y_pred_scaled) # reshape y_test_unscaled = scaler_pred.inverse_transform(y_test.reshape(-1, 1)) # Mean Absolute Error (MAE) MAE = mean_absolute_error(y_test_unscaled, y_pred) print(f'Median Absolute Error (MAE): {np.round(MAE, 2)}') # Mean Absolute Percentage Error (MAPE) MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100 print(f'Mean Absolute Percentage Error (MAPE): {np.round(MAPE, 2)} %') # Median Absolute Percentage Error (MDAPE) MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled)) ) * 100 print(f'Median Absolute Percentage Error (MDAPE): {np.round(MDAPE, 2)} %') # Plot of the true and predicted case counts plt.plot(y_test_unscaled, label='True') plt.plot(y_pred, label='LSTM') plt.title(\u0026quot;LSTM's_Prediction\u0026quot;) plt.xlabel('Time steps') plt.ylabel('Cases') plt.legend() plt.show() # New data frame for predicting the next day count new_df = data_clean[-sequence_length:] # gets the last N days N = sequence_length # Get the values of the last N day closing cases count # scale the data to be values between 0 and 1 last_N_days = new_df[-sequence_length:].values last_N_days_scaled = scaler.transform(last_N_days) # Create an empty list and Append past N days X_test_new = [] X_test_new.append(last_N_days_scaled) # Convert the X_test data set to a numpy array and reshape the data pred_cases_scaled = model_from_saved_checkpoint.predict(np.array(X_test_new)) pred_cases_unscaled = scaler_pred.inverse_transform(pred_cases_scaled.reshape(-1, 1)) # Print last price, predicted price, and change percent for the next day cases_today = np.round(new_df['new_cases_smoothed'][-1]) predicted_cases = np.round(pred_cases_unscaled.ravel()[0]) change_percent = np.round(100 - (cases_today * 100)/predicted_cases) # Code used to produce this article in jupyter notebook in hugo academic blog post !jupyter nbconvert covid_analysis.ipynb --to markdown --NbConvertApp.output_files_dir=. !cat covid_analysis.md | tee -a index.md !rm covid_analysis.md ","date":1585267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585267200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://deepbas.netlify.app/project/internal-project/","publishdate":"2020-03-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Deepak Bastola"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://deepbas.netlify.app/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne **Two** Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}} Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://deepbas.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://deepbas.netlify.app/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Deepak Bastola","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://deepbas.netlify.app/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Deepak Bastola","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://deepbas.netlify.app/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://deepbas.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]