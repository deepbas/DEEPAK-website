<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Bastola" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <script src="https://use.fontawesome.com/5235085b15.js"></script>

    <link rel="stylesheet" href="css/xaringan-themer-solns.css" type="text/css" />
    <link rel="stylesheet" href="css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="css/my-font.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">








layout: true
  
&lt;!-- &lt;div class="my-footer"&gt;&lt;span&gt;Bastola&lt;/span&gt;&lt;/div&gt; --&gt;
&lt;!-- this adds the link footer to all slides, depends on my-footer class in css--&gt;

---
class: title-slide, middle
&lt;!-- background-image: url("assets/title-image2.jpg") --&gt;
background-position: 10% 90%, 100% 50%
background-size: 160px, 100% 100%

# .fancy[Regression and Classification]

### .fancy[Stat 220]

.large[Bastola]

 March 02 2022

---

class: middle

# Resampling methods

.pull-left[
&lt;br&gt;

&lt;br&gt;

&gt; Create a series of data sets similar to the training/testing split, always used with the training set
]

.pull-right[
![](images/resampling.svg)]

.footnote[[Kuhn and Johnson (2019)](https://bookdown.org/max/FES/resampling.html)]

---

class: middle

# First, simple linear regression (SLR)

&gt; Predicting a numeric outcome when there is just one predictor

$$ Y = \beta_0 + \beta_1 X$$
- `\(\beta\)` values are the coefficients and `\(X\)` is the only model predictor or feature.

---

# Bivariate data from `PimaIndiansDiabetes2`



.pull-left[
.scroll-box-20[

```
    glucose insulin
4        89      94
5       137     168
7        78      88
9       197     543
14      189     846
15      166     175
17      118     230
19      103      83
20      115      96
21      126     235
25      143     146
26      125     115
28       97     140
29      145     110
32      158     245
33       88      54
36      103     192
40      111     207
41      180      70
44      171     240
51      103      82
52      101      36
53       88      23
54      176     300
55      150     342
57      187     304
58      100     110
60      105     142
64      141     128
69       95      38
70      146     100
71      100      90
72      139     140
74      129     270
83       83      71
86      110     125
88      100      71
89      136     110
92      123     176
93       81      48
95      142      64
96      144     228
98       71      76
99       93      64
100     122     220
104      81      40
106     126     152
108     144     140
109      83      18
110      95      36
111     171     135
112     155     495
113      89      37
115     160     175
120      99      51
121     162     100
123     107     100
126      88      99
127     120     135
128     118      94
129     117     145
131     173     168
133     170     225
135      96      49
136     125     140
137     100      50
138      93      92
140     105     325
143     108      63
145     154     284
148     106     119
151     136     204
153     156     155
154     153     485
157      99      94
158     109     135
159      88      53
160     163     114
162     102     105
163     114     285
166     104     156
170     111      78
172     134     130
174      79      48
175      75      55
176     179     130
178     129     130
182     119      92
187     181     495
188     128      58
189     109     114
190     139     160
192     123      94
196     158     210
198     107      48
199     109      99
200     148     318
204      99      44
205     103     190
207     196     280
209      96      87
214     140     130
215     112     175
216     151     271
217     109     129
218     125     120
221     177     478
224     142     190
225     100      56
226      87      32
229     197     744
230     117      53
232     134     370
233      79      37
235      74      45
237     181     192
242      91      88
244     119     176
245     146     194
248     165     680
249     124     402
253      90      55
255      92     258
259     193     375
260     155     150
261     191     130
266      96      67
272     108      56
274      71      45
276     100      57
278     104     116
280     108     278
282     129     122
283     133     155
286     136     135
287     155     545
288     119     220
289      96      49
290     108      75
291      78      40
292     107      74
293     128     182
294     128     194
296     151     120
297     146     360
298     126     215
299     100     184
302     144     135
303      77      42
306     120     105
307     161     132
308     137     148
309     128     180
310     124     205
312     106     148
313     155      96
314     113      85
316     112      94
317      99      64
319     115     140
321     129     231
324     152      29
326     157     168
327     122     156
329     102     120
330     105      68
332      87      52
335      95      58
336     165     255
339     152     171
341     130     105
342      95      73
346     126     108
347     139      83
349      99      74
354      90      43
357     125     167
359      88      54
360     196     249
361     189     325
365     147     293
366      99      83
369      81      66
370     133     140
371     173     465
373      84      66
374     105      94
375     122     158
376     140     325
377      98      84
378      87      75
380      93      72
381     107      82
383     109     182
384      90      59
385     125     110
386     119      50
389     144     285
390     100      81
391     100     196
393     131     415
394     116      87
396     127     275
397      96     115
403     136      88
406     123     165
410     172     579
412     112     176
413     143     310
414     143      61
415     138     167
416     173     474
420     129     115
421     119     170
422      94      76
423     102      78
425     151     210
426     184     277
428     181     180
429     135     145
430      95     180
432      89      85
433      80      60
442      83      50
443     117     120
446     180      14
447     100      70
448      95      92
449     104      64
450     120      63
451      82      95
453      91     210
455     100     105
458      86      71
459     148     237
460     134      60
461     120      56
463      74      49
466     124     105
467      74      36
468      97     100
470     154     140
477     105     191
478     114     110
479     126      75
481     158     328
483      85      49
484      84     125
486     135     250
487     139     480
488     173     265
491      83      66
494     125     122
498      81      76
499     195     145
500     154     193
501     117      71
504      94      79
507     180      90
508     130     170
509      84      76
512     139     210
515      99      86
516     163     105
517     145     165
520     129     326
521      68      66
522     124     130
527      97      82
528     116     105
529     117     188
531     122     106
533      86      65
535      77      56
539     127     210
540     129     155
541     100     215
542     128     190
544      84      56
545      88      76
546     186     225
547     187     207
548     131     166
549     164      67
552      84     106
554      88      44
555      84     115
556     124     215
562     198     274
563      87      77
564      99      54
566      95      88
567      99      18
568      92     126
569     154     126
570     121     165
573     111      44
574      98     120
575     143     330
576     119      63
577     108     130
585     124     600
589     176     156
592     112     140
594      82     115
595     123     230
596     188     185
598      89      25
600     109     120
604     150     126
607     181     293
608      92      41
609     152     272
610     111     182
611     106     158
612     174     194
613     168     321
615     138     144
618      68      15
621     112     160
624      94     115
626      90      54
632     102      90
634     128     183
638      94      66
639      97      91
640     100      46
641     102     105
645     103     152
646     157     440
647     167     144
648     179     159
649     136     130
651      91     100
652     117     106
653     123      77
655     106     135
656     155     540
657     101      90
658     120     200
660      80      70
663     167     231
664     145     130
666     112     132
669      98     190
670     154     100
671     165     168
673      68      49
674     123     240
680     101     265
681      56      45
683      95     105
686     129     205
689     140     180
690     144     180
693     121      95
694     129     125
696     142     480
697     169     125
699     127     155
701     122     200
705     110     100
708     127     335
710      93     160
711     158     387
712     126      22
714     134     291
716     187     392
717     173     185
719     108     178
722     114     200
723     149     127
724     117     105
727     116     180
731     130      79
733     174     120
734     106     165
737     126     120
739      99     160
741     120     150
742     102      94
743     109     116
745     153     140
746     100     105
748      81      57
749     187     200
752     121      74
754     181     510
756     128     110
761      88      16
764     101     180
766     121     112
```
]
]
.pull-right[
&lt;img src="Day22_files/figure-html/unnamed-chunk-3-1.svg" width="100%" /&gt;
]


---


# Specification for a linear regression model


```r
lm_spec &lt;- linear_reg() %&gt;%
  set_mode("regression") %&gt;%
  set_engine("lm")
```

--


```r
lm_spec
Linear Regression Model Specification (regression)

Computational engine: lm 
```

---
 
# Fitting the model


```r
lm_fit &lt;- lm_spec %&gt;%
  fit(glucose ~ insulin, data = db_slr)

lm_fit
parsnip model object

Fit time:  4ms 

Call:
stats::lm(formula = glucose ~ insulin, data = data)

Coefficients:
(Intercept)      insulin  
    99.0737       0.1509  
```

---

# Getting the fit


```r
lm_fit %&gt;% 
  pluck("fit")

Call:
stats::lm(formula = glucose ~ insulin, data = data)

Coefficients:
(Intercept)      insulin  
    99.0737       0.1509  
```

---


```r
lm_fit %&gt;% 
  pluck("fit") %&gt;%
* summary()

Call:
stats::lm(formula = glucose ~ insulin, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-65.633 -17.361  -5.807  12.626  78.813 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  99.0737     2.0979   47.23   &lt;2e-16 ***
insulin       0.1509     0.0107   14.11   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 25.14 on 390 degrees of freedom
Multiple R-squared:  0.3378,	Adjusted R-squared:  0.3361 
F-statistic:   199 on 1 and 390 DF,  p-value: &lt; 2.2e-16
```


---


```r
predict(lm_fit, new_data = db_slr)
# A tibble: 392 × 1
   .pred
   &lt;dbl&gt;
 1  113.
 2  124.
 3  112.
 4  181.
 5  227.
 6  125.
 7  134.
 8  112.
 9  114.
10  135.
# … with 382 more rows
```

---

# Confidence and Prediction intervals

.pull-left[
.code90[

```r
predict(lm_fit, new_data = db_slr, 
*       type = "conf_int")
# A tibble: 392 × 2
   .pred_lower .pred_upper
         &lt;dbl&gt;       &lt;dbl&gt;
 1        110.        116.
 2        122.        127.
 3        109.        115.
 4        173.        190.
 5        212.        241.
 6        123.        128.
 7        131.        137.
 8        109.        115.
 9        111.        116.
10        132.        138.
# … with 382 more rows
```
]
]
.pull-right[
.code90[

```r
predict(lm_fit, new_data = db_slr, 
*       type = "pred_int")
# A tibble: 392 × 2
   .pred_lower .pred_upper
         &lt;dbl&gt;       &lt;dbl&gt;
 1        63.7        163.
 2        74.9        174.
 3        62.8        162.
 4       131.         231.
 5       175.         278.
 6        76.0        175.
 7        84.3        183.
 8        62.1        161.
 9        64.0        163.
10        85.0        184.
# … with 382 more rows
```

]
]

---

# Confidence and Prediction intervals


&lt;img src="Day22_files/figure-html/unnamed-chunk-12-1.svg" width="60%" style="display: block; margin: auto;" /&gt;


---

class: middle

# Multiple linear regression (MLR)


&gt; Predicting a continuous response with a set of `\(p\)` predictors.
predioc
$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \cdots + \beta_k X_k $$

- `\(\beta_i\)`'s are the coefficients of the model and `\(X_i\)`'s are the predictors.

---

class: middle

# Fitting a MLR


```r
db_mlr &lt;- db %&gt;% select(-diabetes)

lm_fit2 &lt;- lm_spec %&gt;% 
  fit(glucose ~ ., data = db_mlr) 
```

---

# Extract parameter estimates


```r
*tidy(lm_fit2)
# A tibble: 8 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)  60.0       8.44       7.11  5.65e-12
2 pregnant      0.0738    0.523      0.141 8.88e- 1
3 pressure      0.213     0.108      1.98  4.82e- 2
4 triceps       0.0743    0.158      0.471 6.38e- 1
5 insulin       0.133     0.0108    12.3   1.62e-29
6 mass          0.130     0.244      0.535 5.93e- 1
7 pedigree      4.18      3.62       1.15  2.50e- 1
8 age           0.577     0.172      3.36  8.57e- 4
```

---

# Predict new values


```r
predict(lm_fit2, new_data = db_mlr)
# A tibble: 392 × 1
   .pred
   &lt;dbl&gt;
 1  105.
 2  128.
 3  105.
 4  186.
 5  227.
 6  136.
 7  138.
 8  106.
 9  115.
10  137.
# … with 382 more rows
```

---

# Actual and predicted values


```r
bind_cols(
  predict(lm_fit, new_data = db_mlr), db_mlr) %&gt;% select(glucose, .pred)
# A tibble: 392 × 2
   glucose .pred
     &lt;dbl&gt; &lt;dbl&gt;
 1      89  113.
 2     137  124.
 3      78  112.
 4     197  181.
 5     189  227.
 6     166  125.
 7     118  134.
 8     103  112.
 9     115  114.
10     126  135.
# … with 382 more rows
```

---

class: middle

# Data Splitting


```r
set.seed(1234)

db_split &lt;- initial_split(db_mlr, 
                           prop = 0.80, 
                           strata = age, 
                           breaks = 5)

db_train &lt;- training(db_split) 
db_test &lt;- testing(db_split)
```


---

class: middle

# Recipe


```r
db_recipe &lt;- recipe(glucose ~ ., data = db_train) %&gt;%
  step_scale(all_predictors()) %&gt;%
  step_center(all_predictors()) %&gt;% prep()
```

--
.code90[

```r
db_recipe
Recipe

Inputs:

      role #variables
   outcome          1
 predictor          7

Training data contained 311 data points and no missing data.

Operations:

Scaling for pregnant, pressure, triceps, insulin, mass, ped... [trained]
Centering for pregnant, pressure, triceps, insulin, mass, ped... [trained]
```
]

---

# Model Building


```r
lm_spec &lt;- # your model specification
  linear_reg() %&gt;%  # model type
  set_engine(engine = "lm") %&gt;%  # model engine
  set_mode("regression") # model mode
```

--


```r
# Show your model specification
lm_spec
Linear Regression Model Specification (regression)

Computational engine: lm 
```

---

class: middle

# Create workflow


```r
lm_wflow &lt;-
 workflow() %&gt;%
 add_model(lm_spec) %&gt;% 
 add_recipe(db_recipe)
```

---

# Create Validation Set


```r
set.seed(1234)

cv_folds &lt;- vfold_cv(db_train, 
          v = 5, 
          strata = age,
          breaks = 5) 
```

--


```r
cv_folds
#  5-fold cross-validation using stratification 
# A tibble: 5 × 2
  splits           id   
  &lt;list&gt;           &lt;chr&gt;
1 &lt;split [247/64]&gt; Fold1
2 &lt;split [247/64]&gt; Fold2
3 &lt;split [249/62]&gt; Fold3
4 &lt;split [250/61]&gt; Fold4
5 &lt;split [251/60]&gt; Fold5
```

---


# Common metrics for regression


&gt; Root mean square error (RMSE)

- the standard deviation of the residuals (prediction errors)
- smaller is better

--

&gt; Coefficient of determination, `\(R^2\)`

- proportion of the variation in the outcome that is predictable from the predictors
- larger is better

---

# Fit the model

.code90[

```r
get_model &lt;- function(x) {   # Function to extract fit
  extract_fit_parsnip(x) %&gt;% tidy()
}
```
]

--

.code90[

```r
lm_wflow_eval &lt;- lm_wflow %&gt;% 
  fit_resamples(
    resamples = cv_folds,
    metrics = metric_set(rmse, rsq),
    control = control_resamples(
      save_pred = TRUE,
*     extract = get_model)
    ) 
lm_wflow_eval%&gt;%collect_metrics()
# A tibble: 2 × 6
  .metric .estimator   mean     n std_err .config             
  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard   24.8       5  0.870  Preprocessor1_Model1
2 rsq     standard    0.417     5  0.0442 Preprocessor1_Model1
```
]

---

# Last fit and evaluation


```r
last_fit_lm &lt;- last_fit(lm_wflow, split = db_split)
```

--


```r
last_fit_lm %&gt;% 
  collect_metrics()
# A tibble: 2 × 4
  .metric .estimator .estimate .config             
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
1 rmse    standard      24.4   Preprocessor1_Model1
2 rsq     standard       0.312 Preprocessor1_Model1
```

---

# Extract the estimates


```r
lm_wflow_eval$.extracts[[1]][[1]]
[[1]]
# A tibble: 8 × 5
  term        estimate std.error statistic   p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)  124.         1.56    79.5   6.74e-174
2 pregnant      -1.19       2.17    -0.547 5.85e-  1
3 pressure       4.08       1.73     2.36  1.91e-  2
4 triceps        0.392      2.13     0.184 8.54e-  1
5 insulin       15.8        1.68     9.42  4.13e- 18
6 mass           0.923      2.18     0.424 6.72e-  1
7 pedigree       0.323      1.61     0.201 8.41e-  1
8 age            5.85       2.25     2.60  9.92e-  3
```


---

# Logistic Regression

&gt; Binary response, `\(Y\)`,  with a set of `\(p\)` explanatory (predictor, features) variables, `\(X_1,....X_p\)`.
&gt; We model the probability that `\(Y\)` belongs to a particular category.


`$$P(Y = 1 ) = \frac{e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}}{1 + e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}}$$`

`$$\text{Odds} = \frac{P(Y = 1 )}{1 - P(Y = 1 )} = e^{\beta_0 + \beta_1 + \cdots + \beta_pX_p}$$`
`$$\text{Log Odds} = \beta_0 + \beta_1 + \cdots + \beta_pX_p$$`

---

# Logistic regression with just one predictor

&lt;img src="Day22_files/figure-html/unnamed-chunk-30-1.svg" width="60%" style="display: block; margin: auto;" /&gt;


---


# Train and Test Split


```r
# Create data split for train and test
set.seed(1234)
db_single &lt;- db %&gt;% select(diabetes, glucose) 
db_split &lt;- initial_split(db_single, prop = 0.80, strata = diabetes)
```



```r
# Create training data
db_train &lt;- db_split %&gt;%
                    training()

# Create testing data
db_test &lt;- db_split %&gt;%
                    testing()
```

---

class: middle

# Steps

## 1. Call the model function
## 2. Supply the family of the model
## 3. Supply the type of model you want to fit
## 4. Fit the model

---
class: middle



```r
fitted_logistic_model &lt;- logistic_reg() %&gt;% # Call the model function
        # Set the engine/family of the model
        set_engine("glm") %&gt;%
        # Set the mode
        set_mode("classification") %&gt;%
        # Fit the model
        fit(diabetes~., data = db_train)
```

---

class: middle

# Tidy the Summary


```r
tidy(fitted_logistic_model)
# A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)  -6.26     0.718       -8.72 2.90e-18
2 glucose       0.0439   0.00545      8.04 8.81e-16
```

---

# Odds Ratio

`$$ODDS = \frac{probability}{1 - probability}$$`


```r
tidy(fitted_logistic_model, exponentiate = TRUE)
# A tibble: 2 × 5
  term        estimate std.error statistic  p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)  0.00191   0.718       -8.72 2.90e-18
2 glucose      1.04      0.00545      8.04 8.81e-16
```

---

# Threshold for classification

&lt;img src="Day22_files/figure-html/unnamed-chunk-36-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

---

class: action

# &lt;i class="fa fa-pencil-square-o" style="font-size:48px;color:purple"&gt;&amp;nbsp;Your&amp;nbsp;Turn&amp;nbsp;1&lt;/i&gt;    

Please clone the repository on [logistic regression](https://github.com/stat220/21-logistic-regression) to your local folder.

`$$P(Y = 1 ) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}$$`


- Verify that the glucose value of 142.31 gives the probability of having diabetes as 1/2. 

- What value of glucose gives us a probability threshold (of having diabetes) of 0.75?

<div class="countdown" id="timer_621ffb27" style="top:0;right:0;padding:3px 4px;font-size:2em;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---

# Class Prediction

&gt;  Use the predict function and supply the trained model object, test dataset and the type of variable to predict


```r
# Class prediction
pred_class &lt;- predict(fitted_logistic_model, new_data = db_test,
                      type = "class")  # default 0.5 probability threshold
```

---


```r
bind_cols(db_test %&gt;% select(diabetes), pred_class) %&gt;% 
  conf_mat(diabetes, .pred_class) %&gt;% 
  autoplot(type = "heatmap")
```

&lt;img src="Day22_files/figure-html/unnamed-chunk-38-1.svg" width="50%" style="display: block; margin: auto;" /&gt;

---

# Class Probabilities


```r
# Prediction Probabilities
pred_prob &lt;- predict(fitted_logistic_model,
                      new_data = db_test,
                      type = "prob")
```

--

.code90[

```r
db_results &lt;- db_test %&gt;%
  bind_cols(pred_prob) %&gt;%
  mutate(.pred_class = make_two_class_pred(.pred_neg, levels(diabetes), 
                                           threshold = .75)) %&gt;%

  select(diabetes, glucose, contains(".pred"))
```
]

---

# Results

.pull-left-60[
.code75[

```r
head(db_results,12)
   diabetes glucose  .pred_neg  .pred_pos .pred_class
4       neg      89 0.91349756 0.08650244         neg
5       pos     137 0.56272912 0.43727088         pos
9       pos     197 0.08480112 0.91519888         pos
20      pos     115 0.77153063 0.22846937         neg
25      pos     143 0.49728445 0.50271555         pos
26      pos     125 0.68534836 0.31465164         pos
29      neg     145 0.47537870 0.52462130         pos
40      pos     111 0.80097183 0.19902817         neg
44      pos     171 0.22466256 0.77533744         pos
58      neg     100 0.86700622 0.13299378         neg
69      neg      95 0.89031867 0.10968133         neg
89      pos     136 0.57348808 0.42651192         pos
```
]
]
.pull-right-40[
&lt;img src="Day22_files/figure-html/unnamed-chunk-42-1.svg" width="95%" /&gt;
]

---

# Custom Metrics


```r
custom_metrics &lt;- metric_set(accuracy, sens, spec, ppv)

custom_metrics(db_results,
               truth = diabetes,
               estimate = .pred_class)
# A tibble: 4 × 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy binary         0.671
2 sens     binary         0.604
3 spec     binary         0.808
4 ppv      binary         0.865
```

---

# ROC-AUC (Receiver Operator Characteristic- Area Under Curve)

&lt;!-- ROC-AUC is a performance measurement for the classification problem at various thresholds settings --&gt;

&gt;  Uses the class probability estimates to give us a sense of performance across the entire set of potential probability cutoffs



```r
db_results %&gt;% roc_auc(truth = diabetes, .pred_neg)
# A tibble: 1 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 roc_auc binary         0.802
```

- ROC_AUC tells how much the model is capable of distinguishing between classes.

---

# ROC-AUC

&gt;  plotted with TPR/Recall/Sensitivity against the FPR/ (1- Specificity), where TPR is on the y-axis and FPR is on the x-axis

  + ROC curves with area = 1 under the curve (AUC) are perfect classifiers
  + ROC curves with area = 0.5 AUC are just as good as random guesses


&lt;!--If the curve is more close to the line, lower the performance of the classifier, which is no better than a mere random guess. --&gt;


```r
db_results %&gt;%
  roc_curve(truth = diabetes, .pred_neg) %&gt;%
  autoplot()
```

---

# ROC Curve

&lt;img src="Day22_files/figure-html/unnamed-chunk-46-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

---

# Decision boundary

&lt;img src="Day22_files/figure-html/unnamed-chunk-47-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

---

# Let's look at the full model


```r
# Create data split for train and test
set.seed(1234)
db_split &lt;- initial_split(db, prop = 0.80, strata = diabetes)
```



```r
# Create training data
db_train &lt;- db_split %&gt;%
                    training()

# Create testing data
db_test &lt;- db_split %&gt;%
                    testing()
```

---

# Model Tuning with a Cross Validation


```r
set.seed(100)

cv_folds &lt;-
 vfold_cv(db_train, 
          v = 5, 
          strata = diabetes)
```

---

# Recipe


```r
db_recipe &lt;- recipe(diabetes ~ ., data = db_train) %&gt;%
  step_scale(all_predictors()) %&gt;%
  step_center(all_predictors()) %&gt;% prep()
```


# Specify the model


```r
log_spec &lt;- # your model specification
  logistic_reg() %&gt;%  # model type
  set_engine(engine = "glm") %&gt;%  # model engine
  set_mode("classification") # model mode
```

---

class: middle

## Workflow


```r
log_wflow &lt;- # new workflow object
 workflow() %&gt;% # use workflow function
 add_recipe(db_recipe) %&gt;%   # use the new recipe
 add_model(log_spec)   # add your model spec
```

---

class: middle

## Fit, tune, and evaluate


```r
log_res_2 &lt;- 
  log_wflow %&gt;% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(
      recall, precision, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE,
      extract = get_model) # use extract function as before
    ) 
```

---

# Extract the model


```r
log_res_2$.extracts[[1]][[1]]
[[1]]
# A tibble: 9 × 5
  term        estimate std.error statistic      p.value
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;
1 (Intercept)   -1.05      0.188    -5.58  0.0000000242
2 pregnant       0.379     0.237     1.60  0.110       
3 glucose        1.30      0.239     5.42  0.0000000580
4 pressure      -0.102     0.182    -0.560 0.576       
5 triceps        0.326     0.225     1.45  0.147       
6 insulin       -0.225     0.198    -1.14  0.255       
7 mass           0.461     0.238     1.94  0.0530      
8 pedigree       0.422     0.184     2.29  0.0219      
9 age            0.367     0.241     1.52  0.128       
```

---

class: middle

## Collect the metrics


```r
log_res_2 %&gt;%  collect_metrics(summarize = TRUE)
# A tibble: 7 × 6
  .metric   .estimator  mean     n std_err .config             
  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
1 accuracy  binary     0.783     5  0.0159 Preprocessor1_Model1
2 kap       binary     0.480     5  0.0405 Preprocessor1_Model1
3 precision binary     0.803     5  0.0139 Preprocessor1_Model1
4 recall    binary     0.895     5  0.0141 Preprocessor1_Model1
5 roc_auc   binary     0.851     5  0.0234 Preprocessor1_Model1
6 sens      binary     0.895     5  0.0141 Preprocessor1_Model1
7 spec      binary     0.558     5  0.0381 Preprocessor1_Model1
```

---


```r
log_pred &lt;- log_res_2 %&gt;%
  collect_predictions()
```

&lt;img src="Day22_files/figure-html/unnamed-chunk-58-1.svg" width="50%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="Day22_files/figure-html/unnamed-chunk-59-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

---

# Optimal cut-off

&lt;img src="Day22_files/figure-html/unnamed-chunk-60-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "googlecode",
"highlightLines": true,
"highlightLanguage": ["r", "css", "yaml"],
"countIncrementalSlides": true,
"slideNumberFormat": "%current%",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(60000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
